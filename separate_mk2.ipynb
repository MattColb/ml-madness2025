{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning both Men and Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bracket_data(CATEGORY):\n",
    "    if CATEGORY == \"mens\":\n",
    "        games = \"\"\"\n",
    "1 Auburn vs. 16 Alabama State/St. Francis PA\n",
    "8 Louisville vs. 9 Creighton\n",
    "5 Michigan vs. 12 UC San Diego\n",
    "4 Texas A&M vs. 13 Yale\n",
    "6 Ole Miss vs. 11 SDSU/North Carolina\n",
    "3 Iowa State vs. 14 Lipscomb\n",
    "7 Marquette vs. 10 New Mexico\n",
    "2 Michigan State vs. 15 Bryant\n",
    "1 Florida vs. 16 Norfolk State\n",
    "8 UConn vs. 9 Oklahoma\n",
    "5 Memphis vs. 12 Colorado State\n",
    "4 Maryland vs. 13 Grand Canyon\n",
    "6 Missouri vs. 11 Drake\n",
    "3 Texas Tech vs. 14 UNC Wilmington\n",
    "7 Kansas vs. 10 Arkansas\n",
    "2 St. John’s vs. 15 Omaha\n",
    "1 Duke vs. 16 American/Mount St. Mary’s\n",
    "8 Mississippi State vs. 9 Baylor\n",
    "5 Oregon vs. 12 Liberty\n",
    "4 Arizona vs. 13 Akron\n",
    "6 BYU vs. 11 VCU\n",
    "3 Wisconsin vs. 14 Montana\n",
    "7 St. Mary’s vs. 10 Vanderbilt\n",
    "2 Alabama vs. 15 Robert Morris\n",
    "1 Houston vs. 16 SIUE\n",
    "8 Gonzaga vs. 9 Georgia\n",
    "5 Clemson vs. 12 McNeese\n",
    "4 Purdue vs. 13 High Point\n",
    "6 Illinois vs. 11 Texas/Xavier\n",
    "3 Kentucky vs. 14 Troy\n",
    "7 UCLA vs. 10 Utah State\n",
    "2 Tennessee vs. 15 Wofford\n",
    "        \"\"\"\n",
    "\n",
    "        matchups = games.split(\"\\n\")[1:-1]\n",
    "        m = [m.split(\" vs. \") for m in matchups]\n",
    "        brck = [re.sub(r'^\\d+\\s+', '', team) for pair in m for team in pair]\n",
    "\n",
    "\n",
    "\n",
    "        bmap = {\n",
    "            \"Ole Miss\":\"Mississippi\",\n",
    "            \"Iowa State\":\"Iowa St\",\n",
    "            \"Michigan State\":\"Michigan St\",\n",
    "            \"Norfolk State\":\"Norfolk St\",\n",
    "            \"UConn\":\"Connecticut\",\n",
    "            \"Colorado State\":\"Colorado St\",\n",
    "            \"St. John’s\":\"St John's\",\n",
    "            \"Omaha\":\"NE Omaha\",\n",
    "            \"Mississippi State\":\"Mississippi St\",\n",
    "            \"St. Mary’s\":\"St Mary's CA\",\n",
    "            \"McNeese\":\"McNeese St\",\n",
    "            \"Utah State\":\"Utah St\",\n",
    "            \"SDSU\":\"South Dakota\",\n",
    "            \"Mount St. Mary’s\":\"Mt St Mary's\",\n",
    "            \"St. Francis PA\":\"St Francis PA\",\n",
    "            \"Alabama State\":\"Alabama St\",\n",
    "            \"American\":\"American Univ\"}\n",
    "    else:\n",
    "        games = \"\"\"\n",
    "No. 1 UCLA vs. No. 16 UC San Diego/Southern\n",
    "No. 8 Richmond vs. No. 9 Georgia Tech\n",
    "No. 4 Baylor vs. No. 13 Grand Canyon\n",
    "No. 5 Ole Miss vs. No. 12 Ball State\n",
    "No. 3 LSU vs. No. 14 San Diego State\n",
    "No. 6 Florida State vs. No. 11 George Mason\n",
    "No. 2 NC State vs. No. 15 Vermont\n",
    "No. 7 Michigan State vs. No. 10 Harvard\n",
    "No. 1 USC vs. No. 16 UNC Greensboro\n",
    "No. 8 California vs. No. 9 Mississippi State\n",
    "No. 4 Kentucky vs. No. 13 Liberty\n",
    "No. 5 Kansas State vs. No. 12 Fairfield\n",
    "No. 3 Oklahoma vs. No. 14 Florida Gulf Coast\n",
    "No. 6 Iowa vs. No. 11 Murray State\n",
    "No. 2 UConn vs. No. 15 Arkansas State\n",
    "No. 7 Oklahoma State vs. No. 10 South Dakota State\n",
    "No. 1 South Carolina vs. No. 16 Tennessee Tech\n",
    "No. 8 Utah vs. No. 9 Indiana\n",
    "No. 4 Maryland vs. No. 13 Norfolk State\n",
    "No. 5 Alabama vs. No. 12 Green Bay\n",
    "No. 3 North Carolina vs. No. 14 Oregon State\n",
    "No. 6 West Virginia vs. No. 11 Columbia/Washington\n",
    "No. 2 Duke vs. No. 15 Lehigh\n",
    "No. 7 Vanderbilt vs. No. 10 Oregon\n",
    "No. 1 Texas vs. No. 16 High Point/William & Mary\n",
    "No. 8 Illinois vs. No. 9 Creighton\n",
    "No. 4 Ohio State vs. No. 13 Montana State\n",
    "No. 5 Tennessee vs. No. 12 South Florida\n",
    "No. 3 Notre Dame vs. No. 14 Stephen F. Austin\n",
    "No. 6 Michigan vs. No. 11 Iowa State/Princeton\n",
    "No. 2 TCU vs. No. 15 Fairleigh Dickinson\n",
    "No. 7 Louisville vs. No. 10 Nebraska\n",
    "        \"\"\"\n",
    "\n",
    "        matchups = games.split(\"\\n\")[1:-1]\n",
    "        m = [m.split(\" vs. \") for m in matchups]\n",
    "        brck = [re.sub(r'^(No\\.\\s*)?\\d+\\s+', '', team).strip() for pair in m for team in pair]\n",
    "\n",
    "        bmap = {\n",
    "            \"Ole Miss\":\"Mississippi\",\n",
    "            \"Ball State\":\"Ball St\",\n",
    "            \"San Diego State\":\"San Diego St\",\n",
    "            \"Florida State\":\"Florida St\",\n",
    "            \"Michigan State\":\"Michigan St\",\n",
    "            \"Mississippi State\":\"Mississippi St\",\n",
    "            \"Kansas State\":\"Kansas St\",\n",
    "            \"Florida Gulf Coast\":\"FGCU\",\n",
    "            \"Murray State\":\"Murray St\",\n",
    "            \"UConn\":\"Connecticut\",\n",
    "            \"Arkansas State\":\"Arkansas St\",\n",
    "            \"Oklahoma State\":\"Oklahoma St\",\n",
    "            \"South Dakota State\":\"South Dakota\",\n",
    "            \"Norfolk State\":\"Norfolk St\",\n",
    "            \"Green Bay\":\"WI Green Bay\",\n",
    "            \"Oregon State\":\"Oregon St\",\n",
    "            \"Ohio State\":\"Ohio St\",\n",
    "            \"Montana State\":\"Montana St\",\n",
    "            \"Stephen F. Austin\":\"SF Austin\",\n",
    "            \"Fairleigh Dickinson\":\"F Dickinson\",\n",
    "            \"Iowa State\":\"Iowa St\",\n",
    "            \"Southern\":\"Southern Univ\"\n",
    "        }\n",
    "\n",
    "    return bmap, brck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(season, tournament, conferences):\n",
    "    all_matches = pd.concat([season, tournament], axis=0).sort_values([\"Season\", \"DayNum\"]).reset_index(drop=True)\n",
    "    all_matches.tail()\n",
    "    all_matches[\"LLoc\"] = all_matches.WLoc\n",
    "    all_matches = all_matches.replace({\"LLoc\":{\"H\":\"A\", \"A\":\"H\", \"N\":\"N\"}})\n",
    "    all_matches.head()\n",
    "    cols = [\"Season\", \"first_id\", \"second_id\"]\n",
    "    all_matches[\"first_id\"] = all_matches[['WTeamID','LTeamID']].min(axis=1)\n",
    "    all_matches[\"second_id\"] = all_matches[['WTeamID','LTeamID']].max(axis=1)\n",
    "    all_matches[\"prob\"] = 0\n",
    "    all_matches.loc[all_matches.first_id == all_matches.WTeamID, \"prob\"] = 1\n",
    "    all_matches[\"game_id\"] = all_matches[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    all_matches.head()\n",
    "    adf = all_matches.drop(columns=[\"first_id\", \"second_id\"])\n",
    "    winning_cols = [c for c in adf.columns if c.startswith(\"W\")]\n",
    "    losing_cols = [c for c in adf.columns if c.startswith(\"L\")]\n",
    "    neutral_cols = [c for c in adf.columns if not(c.startswith(\"W\") or c.startswith(\"L\"))]\n",
    "\n",
    "    #Figure out location for losing team\n",
    "\n",
    "    df_w = adf[neutral_cols+winning_cols+[\"LScore\"]].copy()\n",
    "    df_l = adf[neutral_cols+losing_cols+[\"WScore\"]].copy()\n",
    "\n",
    "    df_w = df_w.rename(columns=lambda x:x[1:] if x.startswith(\"W\") else x)\n",
    "    df_l = df_l.rename(columns=lambda x:x[1:] if x.startswith(\"L\") else x)\n",
    "    df_l = df_l.rename(columns={\"WScore\":\"points_allowed\"})\n",
    "    df_w = df_w.rename(columns={\"LScore\":\"points_allowed\"})\n",
    "\n",
    "    df_w[\"result\"] = 1\n",
    "    df_l[\"result\"] = 0\n",
    "\n",
    "    df = pd.concat([df_w, df_l], ignore_index=True)\n",
    "    df = df.sort_values(by=[\"Season\", \"TeamID\", \"DayNum\"]).reset_index(drop=True)\n",
    "    display(df.isna().sum())\n",
    "    saved_df = df.copy()\n",
    "    df = saved_df.copy()\n",
    "    df = df.sort_values(by=[\"Season\", \"TeamID\", \"DayNum\"]).reset_index(drop=True)\n",
    "    stats = [\"Score\", \"FGM\", \"FGA\", \"FGM3\", \"FGA3\", \"FTM\", \"FTA\", \"OR\", \"DR\", \"Ast\", \"TO\", \"Stl\", \"Blk\", \"PF\", \"points_allowed\"]\n",
    "    cum_stats_cols = [f\"cum_{s}\" for s in stats]\n",
    "\n",
    "    for stat in stats:\n",
    "        df[f\"cum_{stat}\"] = df.groupby([\"Season\", \"TeamID\"])[stat].cumsum().shift(fill_value=0)\n",
    "\n",
    "    df[\"games_won\"] = df.groupby([\"Season\", \"TeamID\"])[\"result\"].cumsum().shift(fill_value=0)\n",
    "\n",
    "    df[\"games_played\"] = df.groupby([\"Season\", \"TeamID\"]).cumcount()\n",
    "\n",
    "    df[\"prev_TeamID\"] = df[\"TeamID\"].shift(1)\n",
    "    for stat in [*cum_stats_cols, \"games_played\", \"games_won\"]:\n",
    "        df.loc[df[\"TeamID\"] != df[\"prev_TeamID\"], stat] = 0\n",
    "\n",
    "    df[\"games_lost\"] = df[\"games_played\"] - df[\"games_won\"]\n",
    "\n",
    "    df[\"win_percentage\"] = df[\"games_won\"]/df[\"games_played\"]\n",
    "\n",
    "    df = df.drop(columns=[\"prev_TeamID\"])\n",
    "\n",
    "    df = pd.merge(df, conferences, how=\"left\", left_on=[\"Season\", \"TeamID\"], right_on=[\"Season\", \"TeamID\"])\n",
    "    print(df.columns)\n",
    "    df.head()\n",
    "    cum_stats = df.drop(columns=stats)\n",
    "\n",
    "    averages = [\"cum_Score\", \"cum_OR\", \"cum_DR\", \"cum_Ast\", \"cum_TO\", \"cum_Stl\", \"cum_Blk\", \"cum_PF\", \"cum_points_allowed\"]\n",
    "    percentages = [(\"cum_FGM\", \"cum_FGA\", \"FG%\"), (\"cum_FGM3\", \"cum_FGA3\", \"FG3%\"), (\"cum_FTM\", \"cum_FTA\", \"FT%\")]\n",
    "\n",
    "    print(cum_stats[cum_stats.games_played == 0].shape)\n",
    "\n",
    "    cum_stats = cum_stats[cum_stats.games_played != 0]\n",
    "\n",
    "    for col in averages:\n",
    "        colname = \"avg_\" + col[4:]\n",
    "        cum_stats[colname] = cum_stats[col] / cum_stats[\"games_played\"]\n",
    "\n",
    "    for make, attempt, new_col in percentages:\n",
    "        cum_stats[new_col] = cum_stats[make] / cum_stats[attempt]\n",
    "\n",
    "    averages = cum_stats.drop(columns=cum_stats_cols)\n",
    "\n",
    "    unimportant_cols = [\"prob\", \"NumOT\", \"result\", \"Loc\"]\n",
    "\n",
    "    averages_to_merge = averages.drop(columns=unimportant_cols)\n",
    "    safe = ['Season', 'DayNum', 'first_id', 'second_id', 'prob', 'game_id', 'NumOT']\n",
    "    fdf = all_matches[safe]\n",
    "    fdf.head()\n",
    "\n",
    "    df_merged = pd.merge(fdf, averages_to_merge, how=\"left\", left_on=[\"Season\", \"DayNum\", \"game_id\", \"first_id\"], right_on=[\"Season\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "    df_merged = df_merged.drop(columns=[\"TeamID\"])\n",
    "    for col in df_merged.columns:\n",
    "        if col not in safe:\n",
    "            df_merged[f\"first_{col}\"] = df_merged[col]\n",
    "            df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "    df_merged = pd.merge(df_merged, averages_to_merge, how=\"left\", left_on=[\"Season\", \"DayNum\", \"game_id\", \"second_id\"], right_on=[\"Season\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "    df_merged.drop(columns=[\"TeamID\"])\n",
    "    for col in df_merged.columns:\n",
    "        if col in safe or col.startswith(\"first_\"):\n",
    "            continue\n",
    "        df_merged[f\"second_{col}\"] = df_merged[col]\n",
    "        df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "    nfg_df = df_merged.dropna()\n",
    "    return nfg_df, averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df, cat):\n",
    "    not_needed = [\"Season\", \"first_id\", \"second_TeamID\", \"second_id\", \"game_id\", \"NumOT\", \"DayNum\"]\n",
    "\n",
    "    df = df.drop(columns=not_needed)\n",
    "\n",
    "    X = df.drop(columns=[\"prob\"])\n",
    "    y = df[\"prob\"]\n",
    "\n",
    "    # Identify categorical columns\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # ColumnTransformer to apply OneHotEncoder only to categorical columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
    "        ],\n",
    "        remainder=\"passthrough\"  # Keep non-categorical columns as they are\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': Integer(10, 1000),\n",
    "        'max_depth': Integer(3, 25),\n",
    "        'learning_rate': Real(0.01, 0.5, prior='log-uniform'),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'colsample_bytree': Real(0.5, 1.0)\n",
    "    }\n",
    "\n",
    "    classifier = XGBClassifier(device=\"cuda\")\n",
    "\n",
    "    grid_search = BayesSearchCV(classifier, param_grid, scoring=\"neg_brier_score\", cv=5, verbose=3, n_iter=25)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\", grid_search)  \n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    print(\"Best set of hyperparameters: \", pipe.named_steps[\"classifier\"].best_params_)\n",
    "    print(\"Best score: \", -pipe.named_steps[\"classifier\"].best_score_)\n",
    "\n",
    "    with open(f\"./model_params/{cat}_{datetime.isoformat(datetime.now())}.json\", \"w\") as f:\n",
    "        temp = pipe.named_steps[\"classifier\"].best_params_\n",
    "        temp[\"score\"] = -pipe.named_steps[\"classifier\"].best_score_\n",
    "        json.dump(temp, f)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(CATEGORY):\n",
    "    if CATEGORY == \"mens\":\n",
    "        season = pd.read_csv(\"./data/MRegularSeasonDetailedResults.csv\")\n",
    "        tournament = pd.read_csv(\"./data/MNCAATourneyDetailedResults.csv\")\n",
    "        conferences = pd.read_csv(\"./data/MTeamConferences.csv\")\n",
    "    else:\n",
    "        season = pd.read_csv(\"./data/WRegularSeasonDetailedResults.csv\")\n",
    "        tournament = pd.read_csv(\"./data/WNCAATourneyDetailedResults.csv\")\n",
    "        conferences = pd.read_csv(\"./data/WTeamConferences.csv\")\n",
    "    return season, tournament, conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(CATEGORY, averages, pipe):\n",
    "    submission = pd.read_csv(\"./data/SampleSubmissionStage2.csv\")\n",
    "    teams = pd.DataFrame(submission[\"ID\"].str.split(\"_\").to_list())\n",
    "    cols = [\"Season\", \"first_team_id\", \"second_team_id\"]\n",
    "    teams.columns = cols\n",
    "    teams = pd.concat([teams, submission], axis=1)\n",
    "    for c in cols:\n",
    "        teams[c] = teams[c].astype(\"int64\")\n",
    "\n",
    "    if CATEGORY == \"mens\":\n",
    "        teams = teams[teams.first_team_id < 2000]\n",
    "    else:\n",
    "        teams = teams[teams.first_team_id > 2000]\n",
    "\n",
    "    temp_avgs = averages.drop(columns=[\"NumOT\", \"prob\", \"Loc\", \"result\"])\n",
    "    data2025 = temp_avgs[temp_avgs.Season == 2025]\n",
    "    last_info = data2025.loc[data2025.groupby([\"TeamID\"])[\"DayNum\"].idxmax()]\n",
    "\n",
    "    d = pd.merge(teams, last_info, how=\"left\", left_on=\"first_team_id\", right_on=\"TeamID\", suffixes=(\"\", \"_first\"))\n",
    "    d=d.drop(columns=[\"Season_first\", \"DayNum\", \"TeamID\", \"game_id\"])\n",
    "    d.columns = [f\"first_{col}\" if col not in teams.columns else col for col in d.columns ]\n",
    "    d.head()\n",
    "    d = pd.merge(d, last_info, how=\"left\", left_on=\"second_team_id\", right_on=\"TeamID\", suffixes=(\"\", \"_second\"))\n",
    "    d = d.drop(columns=[\"Season_second\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "    d.columns = [f\"second_{col}\" if col in last_info.columns else col for col in d.columns ]\n",
    "    d = d.drop(columns=[\"second_Season\", \"first_team_id\", \"second_team_id\"])\n",
    "    d.head()\n",
    "\n",
    "    preds = pipe.predict_proba(d)[:,1]\n",
    "\n",
    "    teams[\"Pred\"] = preds\n",
    "\n",
    "    submission = teams[[\"ID\", \"Pred\"]]\n",
    "    return submission, teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tm_id(tm_name, cpy_tms):\n",
    "    cpy_tms = cpy_tms[[\"TeamName\", \"TeamID\"]]\n",
    "    return cpy_tms.loc[cpy_tms.TeamName == tm_name, \"TeamID\"].iloc[0]\n",
    "\n",
    "def get_result(round, team_df, map, team_names):\n",
    "    round = [\n",
    "        [map.get(round[0], round[0]), 0], \n",
    "        [map.get(round[1], round[1]), 0]\n",
    "    ]\n",
    "    round[0][1] = get_tm_id(round[0][0], team_names)\n",
    "    round[1][1] = get_tm_id(round[1][0], team_names)\n",
    "    round.sort(key=lambda x:x[1])\n",
    "    first = round[0][0]\n",
    "    second = round[1][0]\n",
    "    pred = team_df.loc[(team_df.first_team_name == first) & (team_df.second_team_name == second), \"Pred\"]\n",
    "    # print(pred)\n",
    "    pred = pred.iloc[0]\n",
    "    print(first if pred > .5 else  second, \"beat\", second if pred > .5 else first, \"with a prediction of\", pred if pred > .5 else 1-pred)\n",
    "    return first if pred > .5 else second\n",
    "\n",
    "\n",
    "def team_prediction(bracket, df, map, team_names):\n",
    "    # One round for play ins:\n",
    "    next_round = []\n",
    "    for tm in bracket:\n",
    "        winner = tm\n",
    "        if \"/\" in tm:\n",
    "            winner = get_result(tm.split(\"/\"), df, map, team_names)\n",
    "        next_round.append(winner)\n",
    "    bracket = next_round\n",
    "\n",
    "    #Loop through since they are all 0 when %2\n",
    "    while len(bracket) != 1:\n",
    "        next_round = []\n",
    "        while len(bracket) != 0:\n",
    "            curr_round = []\n",
    "            for i in range(2):\n",
    "                curr_round.append(bracket.pop(0))\n",
    "            winner = get_result(curr_round, df, map, team_names)\n",
    "            next_round.append(winner)\n",
    "        bracket = next_round\n",
    "\n",
    "def print_bracket_results(teams, CATEGORY, brck, bmap):\n",
    "\n",
    "    if CATEGORY == \"mens\":\n",
    "        tms = pd.read_csv(\"./data/MTeams.csv\")\n",
    "    else:\n",
    "        tms = pd.read_csv(\"./data/WTeams.csv\")\n",
    "\n",
    "\n",
    "    cpy_tms = tms.copy()\n",
    "    tms = tms[[\"TeamID\", \"TeamName\"]]\n",
    "\n",
    "    teams = teams.merge(tms, how=\"left\", left_on=\"first_team_id\", right_on=\"TeamID\")\n",
    "    teams[\"first_team_name\"] = teams.TeamName\n",
    "    teams = teams.drop(columns=[\"TeamName\", \"TeamID\"])\n",
    "\n",
    "    teams = teams.merge(tms, how=\"left\", left_on=\"second_team_id\", right_on=\"TeamID\")\n",
    "    teams[\"second_team_name\"] = teams.TeamName\n",
    "    teams = teams.drop(columns=[\"TeamName\", \"TeamID\"])\n",
    "\n",
    "    print(f\"{CATEGORY} BRACKET PREDICTIONS\")\n",
    "    team_prediction(brck, teams, bmap, cpy_tms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index(['Season', 'DayNum', 'NumOT', 'prob', 'game_id', 'TeamID', 'Score',\n",
    "       'Loc', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast',\n",
    "       'TO', 'Stl', 'Blk', 'PF', 'points_allowed', 'result', 'cum_Score',\n",
    "       'cum_FGM', 'cum_FGA', 'cum_FGM3', 'cum_FGA3', 'cum_FTM', 'cum_FTA',\n",
    "       'cum_OR', 'cum_DR', 'cum_Ast', 'cum_TO', 'cum_Stl', 'cum_Blk', 'cum_PF',\n",
    "       'cum_points_allowed', 'games_won', 'games_played', 'games_lost',\n",
    "       'win_percentage', 'ConfAbbrev'],\n",
    "      dtype='object')\n",
    "(7981, 28)\n",
    "Modeling...\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "/home/madeline/march_madness/.venv/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:30:45] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
    "Potential solutions:\n",
    "- Use a data structure that matches the device ordinal in the booster.\n",
    "- Set the device for booster before call to inplace_predict.\n",
    "\n",
    "This warning will only be shown once.\n",
    "\n",
    "  warnings.warn(smsg, UserWarning)\n",
    "[CV 1/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.199 total time=   2.5s\n",
    "[CV 2/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.194 total time=   1.3s\n",
    "[CV 3/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.196 total time=   1.3s\n",
    "[CV 4/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.198 total time=   1.3s\n",
    "[CV 5/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.203 total time=   1.6s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.238 total time=  28.4s\n",
    "[CV 2/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.230 total time=  26.8s\n",
    "[CV 3/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.230 total time=  28.3s\n",
    "[CV 4/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.236 total time=  28.1s\n",
    "[CV 5/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.244 total time=  28.3s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.221 total time= 1.9min\n",
    "[CV 2/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.215 total time= 1.9min\n",
    "[CV 3/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.215 total time= 1.9min\n",
    "[CV 4/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.220 total time= 1.9min\n",
    "[CV 5/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.225 total time= 1.8min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.200 total time=   2.2s\n",
    "[CV 2/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.195 total time=   2.2s\n",
    "[CV 3/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.196 total time=   2.3s\n",
    "[CV 4/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.199 total time=   2.3s\n",
    "[CV 5/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.205 total time=   5.0s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.272 total time=   9.3s\n",
    "[CV 2/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.256 total time=  10.1s\n",
    "[CV 3/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.260 total time=  10.0s\n",
    "[CV 4/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.263 total time=  11.0s\n",
    "[CV 5/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.277 total time=   9.2s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.269 total time=  57.1s\n",
    "[CV 2/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.260 total time=  58.1s\n",
    "[CV 3/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.260 total time=  55.1s\n",
    "[CV 4/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.263 total time=  58.8s\n",
    "[CV 5/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.273 total time=  56.5s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.204 total time=  39.2s\n",
    "[CV 2/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.201 total time=  36.9s\n",
    "[CV 3/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.201 total time=  40.3s\n",
    "[CV 4/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.204 total time=  37.8s\n",
    "[CV 5/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.209 total time=  37.7s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.228 total time= 1.3min\n",
    "[CV 2/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.221 total time= 1.3min\n",
    "[CV 3/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.222 total time= 1.3min\n",
    "[CV 4/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.226 total time= 1.2min\n",
    "[CV 5/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.232 total time= 1.3min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.201 total time=   5.8s\n",
    "[CV 2/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.196 total time=   5.8s\n",
    "[CV 3/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.198 total time=   5.8s\n",
    "[CV 4/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.201 total time=   5.8s\n",
    "[CV 5/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.204 total time=   8.5s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.228 total time=  21.4s\n",
    "[CV 2/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.225 total time=  21.2s\n",
    "[CV 3/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.226 total time=  22.7s\n",
    "[CV 4/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.227 total time=  19.7s\n",
    "[CV 5/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.230 total time=  23.4s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.198 total time=  12.4s\n",
    "[CV 2/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.194 total time=  10.3s\n",
    "[CV 3/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.195 total time=  10.4s\n",
    "[CV 4/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.198 total time=  13.2s\n",
    "[CV 5/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.203 total time=  10.3s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.218 total time=   0.6s\n",
    "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.215 total time=   0.6s\n",
    "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.216 total time=   0.7s\n",
    "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.218 total time=   0.7s\n",
    "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.219 total time=   0.6s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.233 total time=   0.7s\n",
    "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.232 total time=   0.7s\n",
    "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.233 total time=   0.6s\n",
    "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.233 total time=   0.7s\n",
    "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.234 total time=   0.7s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.203 total time= 3.2min\n",
    "[CV 2/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.198 total time= 3.3min\n",
    "[CV 3/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.199 total time= 3.2min\n",
    "[CV 4/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.203 total time= 3.2min\n",
    "[CV 5/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.206 total time= 3.2min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.205 total time= 5.6min\n",
    "[CV 2/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.201 total time= 5.6min\n",
    "[CV 3/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.201 total time= 5.5min\n",
    "[CV 4/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.205 total time= 5.5min\n",
    "[CV 5/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.208 total time= 5.5min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.211 total time= 1.7min\n",
    "[CV 2/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.206 total time= 1.7min\n",
    "[CV 3/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.206 total time= 1.8min\n",
    "[CV 4/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.211 total time= 1.7min\n",
    "[CV 5/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.214 total time= 1.7min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.211 total time= 5.3min\n",
    "[CV 2/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.208 total time= 5.3min\n",
    "[CV 3/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.207 total time= 5.3min\n",
    "[CV 4/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.212 total time= 5.4min\n",
    "[CV 5/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.215 total time= 5.3min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.206 total time=   3.1s\n",
    "[CV 2/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.201 total time=   3.0s\n",
    "[CV 3/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.202 total time=   3.0s\n",
    "[CV 4/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.205 total time=   3.0s\n",
    "[CV 5/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.208 total time=   3.0s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.204 total time=  58.1s\n",
    "[CV 2/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.199 total time=  57.5s\n",
    "[CV 3/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.199 total time=  57.1s\n",
    "[CV 4/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.203 total time=  54.5s\n",
    "[CV 5/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.208 total time=  57.4s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.205 total time= 4.9min\n",
    "[CV 2/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.200 total time= 4.8min\n",
    "[CV 3/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.201 total time= 4.8min\n",
    "[CV 4/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.204 total time= 4.9min\n",
    "[CV 5/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.207 total time= 4.9min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.202 total time=   8.5s\n",
    "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.198 total time=   5.5s\n",
    "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.199 total time=   5.6s\n",
    "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.203 total time=   5.5s\n",
    "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.205 total time=   5.6s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.244 total time= 1.7min\n",
    "[CV 2/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.239 total time= 1.6min\n",
    "[CV 3/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.238 total time= 1.6min\n",
    "[CV 4/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.241 total time= 1.7min\n",
    "[CV 5/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.245 total time= 1.6min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.222 total time=   5.8s\n",
    "[CV 2/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.216 total time=   5.6s\n",
    "[CV 3/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.221 total time=   5.5s\n",
    "[CV 4/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.222 total time=   5.4s\n",
    "[CV 5/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.227 total time=   8.2s\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.202 total time= 1.1min\n",
    "[CV 2/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.197 total time= 1.1min\n",
    "[CV 3/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.198 total time= 1.1min\n",
    "[CV 4/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.201 total time= 1.1min\n",
    "[CV 5/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.206 total time= 1.0min\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[CV 1/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.204 total time=   4.5s\n",
    "[CV 2/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.200 total time=   4.3s\n",
    "[CV 3/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.201 total time=   4.3s\n",
    "[CV 4/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.204 total time=   4.3s\n",
    "[CV 5/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.207 total time=   4.3s\n",
    "Best set of hyperparameters:  OrderedDict([('colsample_bytree', 0.859875153926642), ('learning_rate', 0.02089469229801169), ('max_depth', 6), ('n_estimators', 928), ('subsample', 0.9701079282465561)])\n",
    "Best score:  0.1975681930931877\n",
    "Making Predictions...\n",
    "mens BRACKET PREDICTIONS\n",
    "Alabama St beat St Francis PA with a prediction of 0.5152937\n",
    "North Carolina beat South Dakota with a prediction of 0.81057984\n",
    "Mt St Mary's beat American Univ with a prediction of 0.509496\n",
    "Texas beat Xavier with a prediction of 0.5605127\n",
    "Auburn beat Alabama St with a prediction of 0.9636424\n",
    "Louisville beat Creighton with a prediction of 0.59849626\n",
    "Michigan beat UC San Diego with a prediction of 0.52104735\n",
    "Yale beat Texas A&M with a prediction of 0.55304223\n",
    "Mississippi beat North Carolina with a prediction of 0.6390433\n",
    "Iowa St beat Lipscomb with a prediction of 0.70225596\n",
    "Marquette beat New Mexico with a prediction of 0.52168447\n",
    "Michigan St beat Bryant with a prediction of 0.83779716\n",
    "Florida beat Norfolk St with a prediction of 0.89871526\n",
    "Connecticut beat Oklahoma with a prediction of 0.68535477\n",
    "Memphis beat Colorado St with a prediction of 0.55927634\n",
    "Maryland beat Grand Canyon with a prediction of 0.68470454\n",
    "Missouri beat Drake with a prediction of 0.5275874\n",
    "Texas Tech beat UNC Wilmington with a prediction of 0.68105143\n",
    "Kansas beat Arkansas with a prediction of 0.5931146\n",
    "St John's beat NE Omaha with a prediction of 0.8857349\n",
    "Duke beat Mt St Mary's with a prediction of 0.9305454\n",
    "Mississippi St beat Baylor with a prediction of 0.6084884\n",
    "Oregon beat Liberty with a prediction of 0.66313314\n",
    "Arizona beat Akron with a prediction of 0.5544213\n",
    "VCU beat BYU with a prediction of 0.7003275\n",
    "Wisconsin beat Montana with a prediction of 0.88052833\n",
    "St Mary's CA beat Vanderbilt with a prediction of 0.63441986\n",
    "Alabama beat Robert Morris with a prediction of 0.6469547\n",
    "Houston beat SIUE with a prediction of 0.88632613\n",
    "Gonzaga beat Georgia with a prediction of 0.69100076\n",
    "Clemson beat McNeese St with a prediction of 0.681075\n",
    "Purdue beat High Point with a prediction of 0.53558606\n",
    "Illinois beat Texas with a prediction of 0.60994\n",
    "Kentucky beat Troy with a prediction of 0.65769255\n",
    "Utah St beat UCLA with a prediction of 0.54260963\n",
    "Tennessee beat Wofford with a prediction of 0.8456709\n",
    "Auburn beat Louisville with a prediction of 0.6660342\n",
    "Michigan beat Yale with a prediction of 0.54593396\n",
    "Iowa St beat Mississippi with a prediction of 0.7072686\n",
    "Michigan St beat Marquette with a prediction of 0.6985786\n",
    "Florida beat Connecticut with a prediction of 0.61776114\n",
    "Maryland beat Memphis with a prediction of 0.7135941\n",
    "Texas Tech beat Missouri with a prediction of 0.53481585\n",
    "St John's beat Kansas with a prediction of 0.7506169\n",
    "Duke beat Mississippi St with a prediction of 0.7595846\n",
    "Arizona beat Oregon with a prediction of 0.5310278\n",
    "Wisconsin beat VCU with a prediction of 0.513296\n",
    "St Mary's CA beat Alabama with a prediction of 0.5441308\n",
    "Gonzaga beat Houston with a prediction of 0.5239203\n",
    "Clemson beat Purdue with a prediction of 0.6186115\n",
    "Illinois beat Kentucky with a prediction of 0.67685\n",
    "Tennessee beat Utah St with a prediction of 0.63342243\n",
    "Auburn beat Michigan with a prediction of 0.7088824\n",
    "Michigan St beat Iowa St with a prediction of 0.6270033\n",
    "Florida beat Maryland with a prediction of 0.5379876\n",
    "St John's beat Texas Tech with a prediction of 0.58152586\n",
    "Duke beat Arizona with a prediction of 0.7112074\n",
    "Wisconsin beat St Mary's CA with a prediction of 0.5602983\n",
    "Gonzaga beat Clemson with a prediction of 0.59236413\n",
    "Tennessee beat Illinois with a prediction of 0.6709318\n",
    "Auburn beat Michigan St with a prediction of 0.51428944\n",
    "St John's beat Florida with a prediction of 0.5682152\n",
    "Duke beat Wisconsin with a prediction of 0.67446977\n",
    "Gonzaga beat Tennessee with a prediction of 0.5302639\n",
    "St John's beat Auburn with a prediction of 0.56962526\n",
    "Duke beat Gonzaga with a prediction of 0.59986836\n",
    "Duke beat St John's with a prediction of 0.6167959\n",
    "Cleaning data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Season            0\n",
       "DayNum            0\n",
       "NumOT             0\n",
       "prob              0\n",
       "game_id           0\n",
       "TeamID            0\n",
       "Score             0\n",
       "Loc               0\n",
       "FGM               0\n",
       "FGA               0\n",
       "FGM3              0\n",
       "FGA3              0\n",
       "FTM               0\n",
       "FTA               0\n",
       "OR                0\n",
       "DR                0\n",
       "Ast               0\n",
       "TO                0\n",
       "Stl               0\n",
       "Blk               0\n",
       "PF                0\n",
       "points_allowed    0\n",
       "result            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'DayNum', 'NumOT', 'prob', 'game_id', 'TeamID', 'Score',\n",
      "       'Loc', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast',\n",
      "       'TO', 'Stl', 'Blk', 'PF', 'points_allowed', 'result', 'cum_Score',\n",
      "       'cum_FGM', 'cum_FGA', 'cum_FGM3', 'cum_FGA3', 'cum_FTM', 'cum_FTA',\n",
      "       'cum_OR', 'cum_DR', 'cum_Ast', 'cum_TO', 'cum_Stl', 'cum_Blk', 'cum_PF',\n",
      "       'cum_points_allowed', 'games_won', 'games_played', 'games_lost',\n",
      "       'win_percentage', 'ConfAbbrev'],\n",
      "      dtype='object')\n",
      "(7981, 28)\n",
      "Modeling...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madeline/march_madness/.venv/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:30:45] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.199 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.194 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.196 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.198 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.5240788463623524, learning_rate=0.17095758926751753, max_depth=4, n_estimators=154, subsample=0.8118731565165702;, score=-0.203 total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.238 total time=  28.4s\n",
      "[CV 2/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.230 total time=  26.8s\n",
      "[CV 3/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.230 total time=  28.3s\n",
      "[CV 4/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.236 total time=  28.1s\n",
      "[CV 5/5] END colsample_bytree=0.7567926355213533, learning_rate=0.24215877969143518, max_depth=13, n_estimators=371, subsample=0.9743764672194786;, score=-0.244 total time=  28.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.221 total time= 1.9min\n",
      "[CV 2/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.215 total time= 1.9min\n",
      "[CV 3/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.215 total time= 1.9min\n",
      "[CV 4/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.220 total time= 1.9min\n",
      "[CV 5/5] END colsample_bytree=0.7452359399706149, learning_rate=0.04976762602121671, max_depth=16, n_estimators=867, subsample=0.527636971848315;, score=-0.225 total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.200 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.195 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.196 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.199 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.9083182797725724, learning_rate=0.14487253680485826, max_depth=5, n_estimators=214, subsample=0.7244039767418845;, score=-0.205 total time=   5.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.272 total time=   9.3s\n",
      "[CV 2/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.256 total time=  10.1s\n",
      "[CV 3/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.260 total time=  10.0s\n",
      "[CV 4/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.263 total time=  11.0s\n",
      "[CV 5/5] END colsample_bytree=0.9102168048755042, learning_rate=0.3998797701650731, max_depth=7, n_estimators=573, subsample=0.5517081527352217;, score=-0.277 total time=   9.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.269 total time=  57.1s\n",
      "[CV 2/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.260 total time=  58.1s\n",
      "[CV 3/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.260 total time=  55.1s\n",
      "[CV 4/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.263 total time=  58.8s\n",
      "[CV 5/5] END colsample_bytree=0.7507618473191144, learning_rate=0.3535917305934535, max_depth=20, n_estimators=885, subsample=0.624908831212835;, score=-0.273 total time=  56.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.204 total time=  39.2s\n",
      "[CV 2/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.201 total time=  36.9s\n",
      "[CV 3/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.201 total time=  40.3s\n",
      "[CV 4/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.204 total time=  37.8s\n",
      "[CV 5/5] END colsample_bytree=0.5949486627374695, learning_rate=0.04616889380056079, max_depth=18, n_estimators=100, subsample=0.7551629433654146;, score=-0.209 total time=  37.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.228 total time= 1.3min\n",
      "[CV 2/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.221 total time= 1.3min\n",
      "[CV 3/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.222 total time= 1.3min\n",
      "[CV 4/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.226 total time= 1.2min\n",
      "[CV 5/5] END colsample_bytree=0.9881152654495023, learning_rate=0.0981261550052628, max_depth=18, n_estimators=489, subsample=0.9311807768312271;, score=-0.232 total time= 1.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.201 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.196 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.198 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.201 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.8946918904000343, learning_rate=0.013290206460693262, max_depth=4, n_estimators=806, subsample=0.7931730831533674;, score=-0.204 total time=   8.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.228 total time=  21.4s\n",
      "[CV 2/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.225 total time=  21.2s\n",
      "[CV 3/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.226 total time=  22.7s\n",
      "[CV 4/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.227 total time=  19.7s\n",
      "[CV 5/5] END colsample_bytree=0.9846841437276848, learning_rate=0.010690594363866742, max_depth=20, n_estimators=35, subsample=0.6984926672869631;, score=-0.230 total time=  23.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.198 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.194 total time=  10.3s\n",
      "[CV 3/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.195 total time=  10.4s\n",
      "[CV 4/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.198 total time=  13.2s\n",
      "[CV 5/5] END colsample_bytree=0.859875153926642, learning_rate=0.02089469229801169, max_depth=6, n_estimators=928, subsample=0.9701079282465561;, score=-0.203 total time=  10.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.218 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.215 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.216 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.218 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.10507287392524874, max_depth=3, n_estimators=10, subsample=0.5139204651682341;, score=-0.219 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.233 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.232 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.233 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.233 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.030885403452728673, max_depth=5, n_estimators=10, subsample=0.8378602349947626;, score=-0.234 total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.203 total time= 3.2min\n",
      "[CV 2/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.198 total time= 3.3min\n",
      "[CV 3/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.199 total time= 3.2min\n",
      "[CV 4/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.203 total time= 3.2min\n",
      "[CV 5/5] END colsample_bytree=0.8632295146086023, learning_rate=0.010109770550575053, max_depth=25, n_estimators=377, subsample=0.6173244673859046;, score=-0.206 total time= 3.2min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.205 total time= 5.6min\n",
      "[CV 2/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.201 total time= 5.6min\n",
      "[CV 3/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.201 total time= 5.5min\n",
      "[CV 4/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.205 total time= 5.5min\n",
      "[CV 5/5] END colsample_bytree=0.6423206560386095, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.5285320827765579;, score=-0.208 total time= 5.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.211 total time= 1.7min\n",
      "[CV 2/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.206 total time= 1.7min\n",
      "[CV 3/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.206 total time= 1.8min\n",
      "[CV 4/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.211 total time= 1.7min\n",
      "[CV 5/5] END colsample_bytree=0.5162590910800271, learning_rate=0.04340942902978675, max_depth=25, n_estimators=258, subsample=0.889186782957693;, score=-0.214 total time= 1.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.211 total time= 5.3min\n",
      "[CV 2/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.208 total time= 5.3min\n",
      "[CV 3/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.207 total time= 5.3min\n",
      "[CV 4/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.212 total time= 5.4min\n",
      "[CV 5/5] END colsample_bytree=0.6392475582944646, learning_rate=0.01704794997943932, max_depth=25, n_estimators=1000, subsample=0.8416232717882166;, score=-0.215 total time= 5.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.206 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.201 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.202 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.205 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.9209312471042967, learning_rate=0.01, max_depth=3, n_estimators=460, subsample=0.5033336379918557;, score=-0.208 total time=   3.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.204 total time=  58.1s\n",
      "[CV 2/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.199 total time=  57.5s\n",
      "[CV 3/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.199 total time=  57.1s\n",
      "[CV 4/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.203 total time=  54.5s\n",
      "[CV 5/5] END colsample_bytree=0.8930099635437758, learning_rate=0.026063156291301653, max_depth=11, n_estimators=1000, subsample=0.9757408049134444;, score=-0.208 total time=  57.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.205 total time= 4.9min\n",
      "[CV 2/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.200 total time= 4.8min\n",
      "[CV 3/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.201 total time= 4.8min\n",
      "[CV 4/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.204 total time= 4.9min\n",
      "[CV 5/5] END colsample_bytree=0.936152084853387, learning_rate=0.01, max_depth=25, n_estimators=632, subsample=0.7155064092132014;, score=-0.207 total time= 4.9min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.202 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.198 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.199 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.203 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.5;, score=-0.205 total time=   5.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.244 total time= 1.7min\n",
      "[CV 2/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.239 total time= 1.6min\n",
      "[CV 3/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.238 total time= 1.6min\n",
      "[CV 4/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.241 total time= 1.7min\n",
      "[CV 5/5] END colsample_bytree=0.5465182941436568, learning_rate=0.15355533105669106, max_depth=23, n_estimators=1000, subsample=0.7572954723091451;, score=-0.245 total time= 1.6min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.222 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.216 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.221 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.222 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.5228139987554592, learning_rate=0.24128478473922038, max_depth=25, n_estimators=10, subsample=0.6138611760691632;, score=-0.227 total time=   8.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.202 total time= 1.1min\n",
      "[CV 2/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.197 total time= 1.1min\n",
      "[CV 3/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.198 total time= 1.1min\n",
      "[CV 4/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.201 total time= 1.1min\n",
      "[CV 5/5] END colsample_bytree=0.9600409814283288, learning_rate=0.01852852869335224, max_depth=13, n_estimators=541, subsample=0.7217628005105772;, score=-0.206 total time= 1.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.204 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.200 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.201 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.204 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.9753955984918199, learning_rate=0.01, max_depth=3, n_estimators=725, subsample=1.0;, score=-0.207 total time=   4.3s\n",
      "Best set of hyperparameters:  OrderedDict([('colsample_bytree', 0.859875153926642), ('learning_rate', 0.02089469229801169), ('max_depth', 6), ('n_estimators', 928), ('subsample', 0.9701079282465561)])\n",
      "Best score:  0.1975681930931877\n",
      "Making Predictions...\n",
      "mens BRACKET PREDICTIONS\n",
      "Alabama St beat St Francis PA with a prediction of 0.5152937\n",
      "North Carolina beat South Dakota with a prediction of 0.81057984\n",
      "Mt St Mary's beat American Univ with a prediction of 0.509496\n",
      "Texas beat Xavier with a prediction of 0.5605127\n",
      "Auburn beat Alabama St with a prediction of 0.9636424\n",
      "Louisville beat Creighton with a prediction of 0.59849626\n",
      "Michigan beat UC San Diego with a prediction of 0.52104735\n",
      "Yale beat Texas A&M with a prediction of 0.55304223\n",
      "Mississippi beat North Carolina with a prediction of 0.6390433\n",
      "Iowa St beat Lipscomb with a prediction of 0.70225596\n",
      "Marquette beat New Mexico with a prediction of 0.52168447\n",
      "Michigan St beat Bryant with a prediction of 0.83779716\n",
      "Florida beat Norfolk St with a prediction of 0.89871526\n",
      "Connecticut beat Oklahoma with a prediction of 0.68535477\n",
      "Memphis beat Colorado St with a prediction of 0.55927634\n",
      "Maryland beat Grand Canyon with a prediction of 0.68470454\n",
      "Missouri beat Drake with a prediction of 0.5275874\n",
      "Texas Tech beat UNC Wilmington with a prediction of 0.68105143\n",
      "Kansas beat Arkansas with a prediction of 0.5931146\n",
      "St John's beat NE Omaha with a prediction of 0.8857349\n",
      "Duke beat Mt St Mary's with a prediction of 0.9305454\n",
      "Mississippi St beat Baylor with a prediction of 0.6084884\n",
      "Oregon beat Liberty with a prediction of 0.66313314\n",
      "Arizona beat Akron with a prediction of 0.5544213\n",
      "VCU beat BYU with a prediction of 0.7003275\n",
      "Wisconsin beat Montana with a prediction of 0.88052833\n",
      "St Mary's CA beat Vanderbilt with a prediction of 0.63441986\n",
      "Alabama beat Robert Morris with a prediction of 0.6469547\n",
      "Houston beat SIUE with a prediction of 0.88632613\n",
      "Gonzaga beat Georgia with a prediction of 0.69100076\n",
      "Clemson beat McNeese St with a prediction of 0.681075\n",
      "Purdue beat High Point with a prediction of 0.53558606\n",
      "Illinois beat Texas with a prediction of 0.60994\n",
      "Kentucky beat Troy with a prediction of 0.65769255\n",
      "Utah St beat UCLA with a prediction of 0.54260963\n",
      "Tennessee beat Wofford with a prediction of 0.8456709\n",
      "Auburn beat Louisville with a prediction of 0.6660342\n",
      "Michigan beat Yale with a prediction of 0.54593396\n",
      "Iowa St beat Mississippi with a prediction of 0.7072686\n",
      "Michigan St beat Marquette with a prediction of 0.6985786\n",
      "Florida beat Connecticut with a prediction of 0.61776114\n",
      "Maryland beat Memphis with a prediction of 0.7135941\n",
      "Texas Tech beat Missouri with a prediction of 0.53481585\n",
      "St John's beat Kansas with a prediction of 0.7506169\n",
      "Duke beat Mississippi St with a prediction of 0.7595846\n",
      "Arizona beat Oregon with a prediction of 0.5310278\n",
      "Wisconsin beat VCU with a prediction of 0.513296\n",
      "St Mary's CA beat Alabama with a prediction of 0.5441308\n",
      "Gonzaga beat Houston with a prediction of 0.5239203\n",
      "Clemson beat Purdue with a prediction of 0.6186115\n",
      "Illinois beat Kentucky with a prediction of 0.67685\n",
      "Tennessee beat Utah St with a prediction of 0.63342243\n",
      "Auburn beat Michigan with a prediction of 0.7088824\n",
      "Michigan St beat Iowa St with a prediction of 0.6270033\n",
      "Florida beat Maryland with a prediction of 0.5379876\n",
      "St John's beat Texas Tech with a prediction of 0.58152586\n",
      "Duke beat Arizona with a prediction of 0.7112074\n",
      "Wisconsin beat St Mary's CA with a prediction of 0.5602983\n",
      "Gonzaga beat Clemson with a prediction of 0.59236413\n",
      "Tennessee beat Illinois with a prediction of 0.6709318\n",
      "Auburn beat Michigan St with a prediction of 0.51428944\n",
      "St John's beat Florida with a prediction of 0.5682152\n",
      "Duke beat Wisconsin with a prediction of 0.67446977\n",
      "Gonzaga beat Tennessee with a prediction of 0.5302639\n",
      "St John's beat Auburn with a prediction of 0.56962526\n",
      "Duke beat Gonzaga with a prediction of 0.59986836\n",
      "Duke beat St John's with a prediction of 0.6167959\n",
      "Cleaning data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Season            0\n",
       "DayNum            0\n",
       "NumOT             0\n",
       "prob              0\n",
       "game_id           0\n",
       "TeamID            0\n",
       "Score             0\n",
       "Loc               0\n",
       "FGM               0\n",
       "FGA               0\n",
       "FGM3              0\n",
       "FGA3              0\n",
       "FTM               0\n",
       "FTA               0\n",
       "OR                0\n",
       "DR                0\n",
       "Ast               0\n",
       "TO                0\n",
       "Stl               0\n",
       "Blk               0\n",
       "PF                0\n",
       "points_allowed    0\n",
       "result            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'DayNum', 'NumOT', 'prob', 'game_id', 'TeamID', 'Score',\n",
      "       'Loc', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast',\n",
      "       'TO', 'Stl', 'Blk', 'PF', 'points_allowed', 'result', 'cum_Score',\n",
      "       'cum_FGM', 'cum_FGA', 'cum_FGM3', 'cum_FGA3', 'cum_FTM', 'cum_FTA',\n",
      "       'cum_OR', 'cum_DR', 'cum_Ast', 'cum_TO', 'cum_Stl', 'cum_Blk', 'cum_PF',\n",
      "       'cum_points_allowed', 'games_won', 'games_played', 'games_lost',\n",
      "       'win_percentage', 'ConfAbbrev'],\n",
      "      dtype='object')\n",
      "(5602, 28)\n",
      "Modeling...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8452473300942064, learning_rate=0.0627903460535773, max_depth=17, n_estimators=358, subsample=0.8995668303438928;, score=-0.203 total time=  50.5s\n",
      "[CV 2/5] END colsample_bytree=0.8452473300942064, learning_rate=0.0627903460535773, max_depth=17, n_estimators=358, subsample=0.8995668303438928;, score=-0.197 total time=  53.6s\n",
      "[CV 3/5] END colsample_bytree=0.8452473300942064, learning_rate=0.0627903460535773, max_depth=17, n_estimators=358, subsample=0.8995668303438928;, score=-0.193 total time=  52.2s\n",
      "[CV 4/5] END colsample_bytree=0.8452473300942064, learning_rate=0.0627903460535773, max_depth=17, n_estimators=358, subsample=0.8995668303438928;, score=-0.201 total time=  50.4s\n",
      "[CV 5/5] END colsample_bytree=0.8452473300942064, learning_rate=0.0627903460535773, max_depth=17, n_estimators=358, subsample=0.8995668303438928;, score=-0.194 total time=  53.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.618649837738214, learning_rate=0.35567019689486623, max_depth=6, n_estimators=371, subsample=0.6595327736616707;, score=-0.218 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.618649837738214, learning_rate=0.35567019689486623, max_depth=6, n_estimators=371, subsample=0.6595327736616707;, score=-0.213 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.618649837738214, learning_rate=0.35567019689486623, max_depth=6, n_estimators=371, subsample=0.6595327736616707;, score=-0.207 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.618649837738214, learning_rate=0.35567019689486623, max_depth=6, n_estimators=371, subsample=0.6595327736616707;, score=-0.216 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=0.618649837738214, learning_rate=0.35567019689486623, max_depth=6, n_estimators=371, subsample=0.6595327736616707;, score=-0.215 total time=   6.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.945537750736695, learning_rate=0.053296850340592894, max_depth=5, n_estimators=857, subsample=0.7636596767158297;, score=-0.186 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.945537750736695, learning_rate=0.053296850340592894, max_depth=5, n_estimators=857, subsample=0.7636596767158297;, score=-0.181 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.945537750736695, learning_rate=0.053296850340592894, max_depth=5, n_estimators=857, subsample=0.7636596767158297;, score=-0.177 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.945537750736695, learning_rate=0.053296850340592894, max_depth=5, n_estimators=857, subsample=0.7636596767158297;, score=-0.184 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.945537750736695, learning_rate=0.053296850340592894, max_depth=5, n_estimators=857, subsample=0.7636596767158297;, score=-0.180 total time=   9.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5314789706249436, learning_rate=0.09059596202231567, max_depth=5, n_estimators=180, subsample=0.5751113027306706;, score=-0.186 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.5314789706249436, learning_rate=0.09059596202231567, max_depth=5, n_estimators=180, subsample=0.5751113027306706;, score=-0.182 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.5314789706249436, learning_rate=0.09059596202231567, max_depth=5, n_estimators=180, subsample=0.5751113027306706;, score=-0.178 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.5314789706249436, learning_rate=0.09059596202231567, max_depth=5, n_estimators=180, subsample=0.5751113027306706;, score=-0.184 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.5314789706249436, learning_rate=0.09059596202231567, max_depth=5, n_estimators=180, subsample=0.5751113027306706;, score=-0.179 total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5977455037704794, learning_rate=0.301558985346239, max_depth=15, n_estimators=360, subsample=0.9289349529455607;, score=-0.231 total time=  23.9s\n",
      "[CV 2/5] END colsample_bytree=0.5977455037704794, learning_rate=0.301558985346239, max_depth=15, n_estimators=360, subsample=0.9289349529455607;, score=-0.220 total time=  22.8s\n",
      "[CV 3/5] END colsample_bytree=0.5977455037704794, learning_rate=0.301558985346239, max_depth=15, n_estimators=360, subsample=0.9289349529455607;, score=-0.216 total time=  23.9s\n",
      "[CV 4/5] END colsample_bytree=0.5977455037704794, learning_rate=0.301558985346239, max_depth=15, n_estimators=360, subsample=0.9289349529455607;, score=-0.226 total time=  21.8s\n",
      "[CV 5/5] END colsample_bytree=0.5977455037704794, learning_rate=0.301558985346239, max_depth=15, n_estimators=360, subsample=0.9289349529455607;, score=-0.221 total time=  23.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8802195606730985, learning_rate=0.2938439368583162, max_depth=3, n_estimators=635, subsample=0.5607018926631671;, score=-0.194 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.8802195606730985, learning_rate=0.2938439368583162, max_depth=3, n_estimators=635, subsample=0.5607018926631671;, score=-0.189 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.8802195606730985, learning_rate=0.2938439368583162, max_depth=3, n_estimators=635, subsample=0.5607018926631671;, score=-0.184 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.8802195606730985, learning_rate=0.2938439368583162, max_depth=3, n_estimators=635, subsample=0.5607018926631671;, score=-0.191 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.8802195606730985, learning_rate=0.2938439368583162, max_depth=3, n_estimators=635, subsample=0.5607018926631671;, score=-0.188 total time=   3.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7437803301397485, learning_rate=0.3519089677377922, max_depth=13, n_estimators=37, subsample=0.7307137814065253;, score=-0.218 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.7437803301397485, learning_rate=0.3519089677377922, max_depth=13, n_estimators=37, subsample=0.7307137814065253;, score=-0.210 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.7437803301397485, learning_rate=0.3519089677377922, max_depth=13, n_estimators=37, subsample=0.7307137814065253;, score=-0.206 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=0.7437803301397485, learning_rate=0.3519089677377922, max_depth=13, n_estimators=37, subsample=0.7307137814065253;, score=-0.211 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.7437803301397485, learning_rate=0.3519089677377922, max_depth=13, n_estimators=37, subsample=0.7307137814065253;, score=-0.209 total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8454310541595922, learning_rate=0.019815227297354344, max_depth=19, n_estimators=305, subsample=0.9521033580069048;, score=-0.195 total time= 1.7min\n",
      "[CV 2/5] END colsample_bytree=0.8454310541595922, learning_rate=0.019815227297354344, max_depth=19, n_estimators=305, subsample=0.9521033580069048;, score=-0.189 total time= 1.7min\n",
      "[CV 3/5] END colsample_bytree=0.8454310541595922, learning_rate=0.019815227297354344, max_depth=19, n_estimators=305, subsample=0.9521033580069048;, score=-0.185 total time= 1.8min\n",
      "[CV 4/5] END colsample_bytree=0.8454310541595922, learning_rate=0.019815227297354344, max_depth=19, n_estimators=305, subsample=0.9521033580069048;, score=-0.193 total time= 1.7min\n",
      "[CV 5/5] END colsample_bytree=0.8454310541595922, learning_rate=0.019815227297354344, max_depth=19, n_estimators=305, subsample=0.9521033580069048;, score=-0.185 total time= 1.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9032500685383287, learning_rate=0.02101198084478502, max_depth=4, n_estimators=244, subsample=0.5409960050212022;, score=-0.190 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.9032500685383287, learning_rate=0.02101198084478502, max_depth=4, n_estimators=244, subsample=0.5409960050212022;, score=-0.185 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.9032500685383287, learning_rate=0.02101198084478502, max_depth=4, n_estimators=244, subsample=0.5409960050212022;, score=-0.182 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.9032500685383287, learning_rate=0.02101198084478502, max_depth=4, n_estimators=244, subsample=0.5409960050212022;, score=-0.186 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.9032500685383287, learning_rate=0.02101198084478502, max_depth=4, n_estimators=244, subsample=0.5409960050212022;, score=-0.181 total time=   1.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5471836430735223, learning_rate=0.4152472235550389, max_depth=23, n_estimators=41, subsample=0.7216597499001078;, score=-0.229 total time=  11.2s\n",
      "[CV 2/5] END colsample_bytree=0.5471836430735223, learning_rate=0.4152472235550389, max_depth=23, n_estimators=41, subsample=0.7216597499001078;, score=-0.220 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=0.5471836430735223, learning_rate=0.4152472235550389, max_depth=23, n_estimators=41, subsample=0.7216597499001078;, score=-0.220 total time=   8.3s\n",
      "[CV 4/5] END colsample_bytree=0.5471836430735223, learning_rate=0.4152472235550389, max_depth=23, n_estimators=41, subsample=0.7216597499001078;, score=-0.228 total time=   7.8s\n",
      "[CV 5/5] END colsample_bytree=0.5471836430735223, learning_rate=0.4152472235550389, max_depth=23, n_estimators=41, subsample=0.7216597499001078;, score=-0.220 total time=  10.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.08586703540061047, max_depth=4, n_estimators=252, subsample=0.5;, score=-0.185 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.08586703540061047, max_depth=4, n_estimators=252, subsample=0.5;, score=-0.181 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.08586703540061047, max_depth=4, n_estimators=252, subsample=0.5;, score=-0.177 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.08586703540061047, max_depth=4, n_estimators=252, subsample=0.5;, score=-0.183 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.08586703540061047, max_depth=4, n_estimators=252, subsample=0.5;, score=-0.178 total time=   1.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.02438211679188603, max_depth=3, n_estimators=648, subsample=0.5961619339422984;, score=-0.188 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.02438211679188603, max_depth=3, n_estimators=648, subsample=0.5961619339422984;, score=-0.183 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.02438211679188603, max_depth=3, n_estimators=648, subsample=0.5961619339422984;, score=-0.179 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.02438211679188603, max_depth=3, n_estimators=648, subsample=0.5961619339422984;, score=-0.184 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.02438211679188603, max_depth=3, n_estimators=648, subsample=0.5961619339422984;, score=-0.179 total time=   3.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.6840951627955075, learning_rate=0.05239116882257373, max_depth=3, n_estimators=163, subsample=0.96833529372863;, score=-0.191 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.6840951627955075, learning_rate=0.05239116882257373, max_depth=3, n_estimators=163, subsample=0.96833529372863;, score=-0.185 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.6840951627955075, learning_rate=0.05239116882257373, max_depth=3, n_estimators=163, subsample=0.96833529372863;, score=-0.182 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.6840951627955075, learning_rate=0.05239116882257373, max_depth=3, n_estimators=163, subsample=0.96833529372863;, score=-0.186 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.6840951627955075, learning_rate=0.05239116882257373, max_depth=3, n_estimators=163, subsample=0.96833529372863;, score=-0.182 total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=25, n_estimators=86, subsample=0.7872995806080256;, score=-0.204 total time=  37.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=25, n_estimators=86, subsample=0.7872995806080256;, score=-0.201 total time=  36.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=25, n_estimators=86, subsample=0.7872995806080256;, score=-0.198 total time=  34.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=25, n_estimators=86, subsample=0.7872995806080256;, score=-0.200 total time=  38.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=25, n_estimators=86, subsample=0.7872995806080256;, score=-0.200 total time=  36.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8358107135804895, learning_rate=0.018974506396320905, max_depth=5, n_estimators=26, subsample=0.9838730816109265;, score=-0.218 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8358107135804895, learning_rate=0.018974506396320905, max_depth=5, n_estimators=26, subsample=0.9838730816109265;, score=-0.216 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8358107135804895, learning_rate=0.018974506396320905, max_depth=5, n_estimators=26, subsample=0.9838730816109265;, score=-0.214 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8358107135804895, learning_rate=0.018974506396320905, max_depth=5, n_estimators=26, subsample=0.9838730816109265;, score=-0.216 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8358107135804895, learning_rate=0.018974506396320905, max_depth=5, n_estimators=26, subsample=0.9838730816109265;, score=-0.214 total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5712334902226592, learning_rate=0.04059956524742111, max_depth=11, n_estimators=800, subsample=0.5;, score=-0.196 total time=  37.6s\n",
      "[CV 2/5] END colsample_bytree=0.5712334902226592, learning_rate=0.04059956524742111, max_depth=11, n_estimators=800, subsample=0.5;, score=-0.190 total time=  37.9s\n",
      "[CV 3/5] END colsample_bytree=0.5712334902226592, learning_rate=0.04059956524742111, max_depth=11, n_estimators=800, subsample=0.5;, score=-0.186 total time=  38.1s\n",
      "[CV 4/5] END colsample_bytree=0.5712334902226592, learning_rate=0.04059956524742111, max_depth=11, n_estimators=800, subsample=0.5;, score=-0.194 total time=  37.9s\n",
      "[CV 5/5] END colsample_bytree=0.5712334902226592, learning_rate=0.04059956524742111, max_depth=11, n_estimators=800, subsample=0.5;, score=-0.189 total time=  37.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5374322250114295, learning_rate=0.047601921634666214, max_depth=3, n_estimators=734, subsample=0.5;, score=-0.185 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.5374322250114295, learning_rate=0.047601921634666214, max_depth=3, n_estimators=734, subsample=0.5;, score=-0.181 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.5374322250114295, learning_rate=0.047601921634666214, max_depth=3, n_estimators=734, subsample=0.5;, score=-0.176 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.5374322250114295, learning_rate=0.047601921634666214, max_depth=3, n_estimators=734, subsample=0.5;, score=-0.183 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.5374322250114295, learning_rate=0.047601921634666214, max_depth=3, n_estimators=734, subsample=0.5;, score=-0.178 total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8391493904356822, learning_rate=0.08983632871508224, max_depth=3, n_estimators=1000, subsample=0.7623563832154943;, score=-0.185 total time=   7.7s\n",
      "[CV 2/5] END colsample_bytree=0.8391493904356822, learning_rate=0.08983632871508224, max_depth=3, n_estimators=1000, subsample=0.7623563832154943;, score=-0.181 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.8391493904356822, learning_rate=0.08983632871508224, max_depth=3, n_estimators=1000, subsample=0.7623563832154943;, score=-0.176 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.8391493904356822, learning_rate=0.08983632871508224, max_depth=3, n_estimators=1000, subsample=0.7623563832154943;, score=-0.183 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.8391493904356822, learning_rate=0.08983632871508224, max_depth=3, n_estimators=1000, subsample=0.7623563832154943;, score=-0.179 total time=   4.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5162306511034473, learning_rate=0.01, max_depth=16, n_estimators=904, subsample=0.5;, score=-0.189 total time= 2.1min\n",
      "[CV 2/5] END colsample_bytree=0.5162306511034473, learning_rate=0.01, max_depth=16, n_estimators=904, subsample=0.5;, score=-0.184 total time= 2.1min\n",
      "[CV 3/5] END colsample_bytree=0.5162306511034473, learning_rate=0.01, max_depth=16, n_estimators=904, subsample=0.5;, score=-0.180 total time= 2.1min\n",
      "[CV 4/5] END colsample_bytree=0.5162306511034473, learning_rate=0.01, max_depth=16, n_estimators=904, subsample=0.5;, score=-0.186 total time= 2.0min\n",
      "[CV 5/5] END colsample_bytree=0.5162306511034473, learning_rate=0.01, max_depth=16, n_estimators=904, subsample=0.5;, score=-0.181 total time= 2.1min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.925868573247375, learning_rate=0.024484685912236542, max_depth=18, n_estimators=479, subsample=0.5;, score=-0.195 total time= 1.4min\n",
      "[CV 2/5] END colsample_bytree=0.925868573247375, learning_rate=0.024484685912236542, max_depth=18, n_estimators=479, subsample=0.5;, score=-0.189 total time= 1.4min\n",
      "[CV 3/5] END colsample_bytree=0.925868573247375, learning_rate=0.024484685912236542, max_depth=18, n_estimators=479, subsample=0.5;, score=-0.185 total time= 1.4min\n",
      "[CV 4/5] END colsample_bytree=0.925868573247375, learning_rate=0.024484685912236542, max_depth=18, n_estimators=479, subsample=0.5;, score=-0.193 total time= 1.4min\n",
      "[CV 5/5] END colsample_bytree=0.925868573247375, learning_rate=0.024484685912236542, max_depth=18, n_estimators=479, subsample=0.5;, score=-0.186 total time= 1.4min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5214450375496908, learning_rate=0.01, max_depth=15, n_estimators=638, subsample=1.0;, score=-0.190 total time= 2.2min\n",
      "[CV 2/5] END colsample_bytree=0.5214450375496908, learning_rate=0.01, max_depth=15, n_estimators=638, subsample=1.0;, score=-0.185 total time= 2.2min\n",
      "[CV 3/5] END colsample_bytree=0.5214450375496908, learning_rate=0.01, max_depth=15, n_estimators=638, subsample=1.0;, score=-0.181 total time= 2.2min\n",
      "[CV 4/5] END colsample_bytree=0.5214450375496908, learning_rate=0.01, max_depth=15, n_estimators=638, subsample=1.0;, score=-0.188 total time= 2.2min\n",
      "[CV 5/5] END colsample_bytree=0.5214450375496908, learning_rate=0.01, max_depth=15, n_estimators=638, subsample=1.0;, score=-0.181 total time= 2.1min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.190 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.185 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.181 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.186 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.181 total time=   4.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9555405570967452, learning_rate=0.49999999999999994, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.204 total time=   7.9s\n",
      "[CV 2/5] END colsample_bytree=0.9555405570967452, learning_rate=0.49999999999999994, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.196 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.9555405570967452, learning_rate=0.49999999999999994, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.191 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.9555405570967452, learning_rate=0.49999999999999994, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.200 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.9555405570967452, learning_rate=0.49999999999999994, max_depth=3, n_estimators=1000, subsample=1.0;, score=-0.199 total time=   5.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8786723725086212, learning_rate=0.01, max_depth=3, n_estimators=447, subsample=0.5;, score=-0.193 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.8786723725086212, learning_rate=0.01, max_depth=3, n_estimators=447, subsample=0.5;, score=-0.188 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.8786723725086212, learning_rate=0.01, max_depth=3, n_estimators=447, subsample=0.5;, score=-0.184 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.8786723725086212, learning_rate=0.01, max_depth=3, n_estimators=447, subsample=0.5;, score=-0.189 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8786723725086212, learning_rate=0.01, max_depth=3, n_estimators=447, subsample=0.5;, score=-0.184 total time=   2.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7017151883744998, learning_rate=0.11993389294906123, max_depth=3, n_estimators=790, subsample=1.0;, score=-0.185 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.7017151883744998, learning_rate=0.11993389294906123, max_depth=3, n_estimators=790, subsample=1.0;, score=-0.181 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.7017151883744998, learning_rate=0.11993389294906123, max_depth=3, n_estimators=790, subsample=1.0;, score=-0.176 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.7017151883744998, learning_rate=0.11993389294906123, max_depth=3, n_estimators=790, subsample=1.0;, score=-0.183 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.7017151883744998, learning_rate=0.11993389294906123, max_depth=3, n_estimators=790, subsample=1.0;, score=-0.179 total time=   3.9s\n",
      "Best set of hyperparameters:  OrderedDict([('colsample_bytree', 0.5374322250114295), ('learning_rate', 0.047601921634666214), ('max_depth', 3), ('n_estimators', 734), ('subsample', 0.5)])\n",
      "Best score:  0.18056399017993363\n",
      "Making Predictions...\n",
      "womens BRACKET PREDICTIONS\n",
      "UC San Diego beat Southern Univ with a prediction of 0.6022485\n",
      "Columbia beat Washington with a prediction of 0.56928015\n",
      "High Point beat William & Mary with a prediction of 0.68189645\n",
      "Princeton beat Iowa St with a prediction of 0.5244088\n",
      "UCLA beat UC San Diego with a prediction of 0.9611062\n",
      "Richmond beat Georgia Tech with a prediction of 0.56928986\n",
      "Baylor beat Grand Canyon with a prediction of 0.634873\n",
      "Mississippi beat Ball St with a prediction of 0.7981573\n",
      "LSU beat San Diego St with a prediction of 0.84906167\n",
      "Florida St beat George Mason with a prediction of 0.6958773\n",
      "NC State beat Vermont with a prediction of 0.77151835\n",
      "Michigan St beat Harvard with a prediction of 0.63010585\n",
      "USC beat UNC Greensboro with a prediction of 0.8965494\n",
      "California beat Mississippi St with a prediction of 0.50703925\n",
      "Kentucky beat Liberty with a prediction of 0.7608725\n",
      "Kansas St beat Fairfield with a prediction of 0.71821535\n",
      "Oklahoma beat FGCU with a prediction of 0.588659\n",
      "Murray St beat Iowa with a prediction of 0.5326829\n",
      "Connecticut beat Arkansas St with a prediction of 0.9343093\n",
      "Oklahoma St beat South Dakota with a prediction of 0.9546647\n",
      "South Carolina beat Tennessee Tech with a prediction of 0.9054261\n",
      "Utah beat Indiana with a prediction of 0.678839\n",
      "Maryland beat Norfolk St with a prediction of 0.5482922\n",
      "Alabama beat WI Green Bay with a prediction of 0.6093143\n",
      "North Carolina beat Oregon St with a prediction of 0.91979986\n",
      "West Virginia beat Columbia with a prediction of 0.6267531\n",
      "Duke beat Lehigh with a prediction of 0.7125311\n",
      "Vanderbilt beat Oregon with a prediction of 0.7684194\n",
      "Texas beat High Point with a prediction of 0.97619784\n",
      "Creighton beat Illinois with a prediction of 0.62504476\n",
      "Ohio St beat Montana St with a prediction of 0.65573037\n",
      "Tennessee beat South Florida with a prediction of 0.74739003\n",
      "Notre Dame beat SF Austin with a prediction of 0.8628705\n",
      "Princeton beat Michigan with a prediction of 0.5667187\n",
      "TCU beat F Dickinson with a prediction of 0.9078612\n",
      "Louisville beat Nebraska with a prediction of 0.51111346\n",
      "UCLA beat Richmond with a prediction of 0.70384\n",
      "Baylor beat Mississippi with a prediction of 0.5339299\n",
      "LSU beat Florida St with a prediction of 0.64105177\n",
      "NC State beat Michigan St with a prediction of 0.542507\n",
      "USC beat California with a prediction of 0.8408923\n",
      "Kansas St beat Kentucky with a prediction of 0.7691074\n",
      "Oklahoma beat Murray St with a prediction of 0.59449434\n",
      "Connecticut beat Oklahoma St with a prediction of 0.87078655\n",
      "South Carolina beat Utah with a prediction of 0.82631797\n",
      "Alabama beat Maryland with a prediction of 0.5304038\n",
      "West Virginia beat North Carolina with a prediction of 0.5610746\n",
      "Vanderbilt beat Duke with a prediction of 0.5640516\n",
      "Texas beat Creighton with a prediction of 0.9185268\n",
      "Ohio St beat Tennessee with a prediction of 0.51894385\n",
      "Notre Dame beat Princeton with a prediction of 0.788678\n",
      "TCU beat Louisville with a prediction of 0.8989612\n",
      "UCLA beat Baylor with a prediction of 0.7240119\n",
      "LSU beat NC State with a prediction of 0.589842\n",
      "Kansas St beat USC with a prediction of 0.5818488\n",
      "Connecticut beat Oklahoma with a prediction of 0.8558142\n",
      "South Carolina beat Alabama with a prediction of 0.86180675\n",
      "Vanderbilt beat West Virginia with a prediction of 0.5266204\n",
      "Texas beat Ohio St with a prediction of 0.87369746\n",
      "TCU beat Notre Dame with a prediction of 0.5440941\n",
      "UCLA beat LSU with a prediction of 0.7338233\n",
      "Connecticut beat Kansas St with a prediction of 0.7306773\n",
      "South Carolina beat Vanderbilt with a prediction of 0.68098015\n",
      "Texas beat TCU with a prediction of 0.72641623\n",
      "Connecticut beat UCLA with a prediction of 0.67724913\n",
      "Texas beat South Carolina with a prediction of 0.7283708\n",
      "Texas beat Connecticut with a prediction of 0.53109586\n"
     ]
    }
   ],
   "source": [
    "# Running everything\n",
    "results = pd.DataFrame()\n",
    "for cat in [\"mens\", \"womens\"]:\n",
    "    print(\"Cleaning data...\")\n",
    "    season, tournament, conferences = get_data(cat)\n",
    "    df, averages = data_cleaning(season, tournament, conferences)\n",
    "    print(\"Modeling...\")\n",
    "    pipe = model(df, cat)\n",
    "    print(\"Making Predictions...\")\n",
    "    bmap, brck = get_bracket_data(cat)\n",
    "    submission, teams = make_predictions(cat, averages, pipe)\n",
    "    submission.to_csv(f\"./individual_submissions/{cat}_{datetime.isoformat(datetime.now())}\", index=False)\n",
    "    print_bracket_results(teams, cat, brck, bmap)\n",
    "    results = pd.concat([results, submission], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating submission\n",
    "mens = pd.read_csv(\"individual_submissions/mens_2025-03-19T19:05:15.844130.csv\")\n",
    "womens = pd.read_csv(\"individual_submissions/womens_2025-03-19T20:00:51.139226.csv\")\n",
    "combined = pd.concat([mens, womens], axis=0).reset_index(drop=True)\n",
    "combined.to_csv(\"./submissions/final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
