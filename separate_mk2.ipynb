{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning both Men and Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bracket_data(CATEGORY):\n",
    "    if CATEGORY == \"mens\":\n",
    "        games = \"\"\"\n",
    "1 Auburn vs. 16 Alabama State/St. Francis PA\n",
    "8 Louisville vs. 9 Creighton\n",
    "5 Michigan vs. 12 UC San Diego\n",
    "4 Texas A&M vs. 13 Yale\n",
    "6 Ole Miss vs. 11 SDSU/North Carolina\n",
    "3 Iowa State vs. 14 Lipscomb\n",
    "7 Marquette vs. 10 New Mexico\n",
    "2 Michigan State vs. 15 Bryant\n",
    "1 Florida vs. 16 Norfolk State\n",
    "8 UConn vs. 9 Oklahoma\n",
    "5 Memphis vs. 12 Colorado State\n",
    "4 Maryland vs. 13 Grand Canyon\n",
    "6 Missouri vs. 11 Drake\n",
    "3 Texas Tech vs. 14 UNC Wilmington\n",
    "7 Kansas vs. 10 Arkansas\n",
    "2 St. John’s vs. 15 Omaha\n",
    "1 Duke vs. 16 American/Mount St. Mary’s\n",
    "8 Mississippi State vs. 9 Baylor\n",
    "5 Oregon vs. 12 Liberty\n",
    "4 Arizona vs. 13 Akron\n",
    "6 BYU vs. 11 VCU\n",
    "3 Wisconsin vs. 14 Montana\n",
    "7 St. Mary’s vs. 10 Vanderbilt\n",
    "2 Alabama vs. 15 Robert Morris\n",
    "1 Houston vs. 16 SIUE\n",
    "8 Gonzaga vs. 9 Georgia\n",
    "5 Clemson vs. 12 McNeese\n",
    "4 Purdue vs. 13 High Point\n",
    "6 Illinois vs. 11 Texas/Xavier\n",
    "3 Kentucky vs. 14 Troy\n",
    "7 UCLA vs. 10 Utah State\n",
    "2 Tennessee vs. 15 Wofford\n",
    "        \"\"\"\n",
    "\n",
    "        matchups = games.split(\"\\n\")[1:-1]\n",
    "        m = [m.split(\" vs. \") for m in matchups]\n",
    "        brck = [re.sub(r'^\\d+\\s+', '', team) for pair in m for team in pair]\n",
    "\n",
    "\n",
    "\n",
    "        bmap = {\n",
    "            \"Ole Miss\":\"Mississippi\",\n",
    "            \"Iowa State\":\"Iowa St\",\n",
    "            \"Michigan State\":\"Michigan St\",\n",
    "            \"Norfolk State\":\"Norfolk St\",\n",
    "            \"UConn\":\"Connecticut\",\n",
    "            \"Colorado State\":\"Colorado St\",\n",
    "            \"St. John’s\":\"St John's\",\n",
    "            \"Omaha\":\"NE Omaha\",\n",
    "            \"Mississippi State\":\"Mississippi St\",\n",
    "            \"St. Mary’s\":\"St Mary's CA\",\n",
    "            \"McNeese\":\"McNeese St\",\n",
    "            \"Utah State\":\"Utah St\",\n",
    "            \"SDSU\":\"South Dakota\",\n",
    "            \"Mount St. Mary’s\":\"Mt St Mary's\",\n",
    "            \"St. Francis PA\":\"St Francis PA\",\n",
    "            \"Alabama State\":\"Alabama St\",\n",
    "            \"American\":\"American Univ\"}\n",
    "    else:\n",
    "        games = \"\"\"\n",
    "No. 1 UCLA vs. No. 16 UC San Diego/Southern\n",
    "No. 8 Richmond vs. No. 9 Georgia Tech\n",
    "No. 4 Baylor vs. No. 13 Grand Canyon\n",
    "No. 5 Ole Miss vs. No. 12 Ball State\n",
    "No. 3 LSU vs. No. 14 San Diego State\n",
    "No. 6 Florida State vs. No. 11 George Mason\n",
    "No. 2 NC State vs. No. 15 Vermont\n",
    "No. 7 Michigan State vs. No. 10 Harvard\n",
    "No. 1 USC vs. No. 16 UNC Greensboro\n",
    "No. 8 California vs. No. 9 Mississippi State\n",
    "No. 4 Kentucky vs. No. 13 Liberty\n",
    "No. 5 Kansas State vs. No. 12 Fairfield\n",
    "No. 3 Oklahoma vs. No. 14 Florida Gulf Coast\n",
    "No. 6 Iowa vs. No. 11 Murray State\n",
    "No. 2 UConn vs. No. 15 Arkansas State\n",
    "No. 7 Oklahoma State vs. No. 10 South Dakota State\n",
    "No. 1 South Carolina vs. No. 16 Tennessee Tech\n",
    "No. 8 Utah vs. No. 9 Indiana\n",
    "No. 4 Maryland vs. No. 13 Norfolk State\n",
    "No. 5 Alabama vs. No. 12 Green Bay\n",
    "No. 3 North Carolina vs. No. 14 Oregon State\n",
    "No. 6 West Virginia vs. No. 11 Columbia/Washington\n",
    "No. 2 Duke vs. No. 15 Lehigh\n",
    "No. 7 Vanderbilt vs. No. 10 Oregon\n",
    "No. 1 Texas vs. No. 16 High Point/William & Mary\n",
    "No. 8 Illinois vs. No. 9 Creighton\n",
    "No. 4 Ohio State vs. No. 13 Montana State\n",
    "No. 5 Tennessee vs. No. 12 South Florida\n",
    "No. 3 Notre Dame vs. No. 14 Stephen F. Austin\n",
    "No. 6 Michigan vs. No. 11 Iowa State/Princeton\n",
    "No. 2 TCU vs. No. 15 Fairleigh Dickinson\n",
    "No. 7 Louisville vs. No. 10 Nebraska\n",
    "        \"\"\"\n",
    "\n",
    "        matchups = games.split(\"\\n\")[1:-1]\n",
    "        m = [m.split(\" vs. \") for m in matchups]\n",
    "        brck = [re.sub(r'^(No\\.\\s*)?\\d+\\s+', '', team).strip() for pair in m for team in pair]\n",
    "\n",
    "        bmap = {\n",
    "            \"Ole Miss\":\"Mississippi\",\n",
    "            \"Ball State\":\"Ball St\",\n",
    "            \"San Diego State\":\"San Diego St\",\n",
    "            \"Florida State\":\"Florida St\",\n",
    "            \"Michigan State\":\"Michigan St\",\n",
    "            \"Mississippi State\":\"Mississippi St\",\n",
    "            \"Kansas State\":\"Kansas St\",\n",
    "            \"Florida Gulf Coast\":\"FGCU\",\n",
    "            \"Murray State\":\"Murray St\",\n",
    "            \"UConn\":\"Connecticut\",\n",
    "            \"Arkansas State\":\"Arkansas St\",\n",
    "            \"Oklahoma State\":\"Oklahoma St\",\n",
    "            \"South Dakota State\":\"South Dakota\",\n",
    "            \"Norfolk State\":\"Norfolk St\",\n",
    "            \"Green Bay\":\"WI Green Bay\",\n",
    "            \"Oregon State\":\"Oregon St\",\n",
    "            \"Ohio State\":\"Ohio St\",\n",
    "            \"Montana State\":\"Montana St\",\n",
    "            \"Stephen F. Austin\":\"SF Austin\",\n",
    "            \"Fairleigh Dickinson\":\"F Dickinson\",\n",
    "            \"Iowa State\":\"Iowa St\",\n",
    "            \"Southern\":\"Southern Univ\"\n",
    "        }\n",
    "\n",
    "    return bmap, brck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(season, tournament, conferences):\n",
    "    all_matches = pd.concat([season, tournament], axis=0).sort_values([\"Season\", \"DayNum\"]).reset_index(drop=True)\n",
    "    all_matches.tail()\n",
    "    all_matches[\"LLoc\"] = all_matches.WLoc\n",
    "    all_matches = all_matches.replace({\"LLoc\":{\"H\":\"A\", \"A\":\"H\", \"N\":\"N\"}})\n",
    "    all_matches.head()\n",
    "    cols = [\"Season\", \"first_id\", \"second_id\"]\n",
    "    all_matches[\"first_id\"] = all_matches[['WTeamID','LTeamID']].min(axis=1)\n",
    "    all_matches[\"second_id\"] = all_matches[['WTeamID','LTeamID']].max(axis=1)\n",
    "    all_matches[\"prob\"] = 0\n",
    "    all_matches.loc[all_matches.first_id == all_matches.WTeamID, \"prob\"] = 1\n",
    "    all_matches[\"game_id\"] = all_matches[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    all_matches.head()\n",
    "    adf = all_matches.drop(columns=[\"first_id\", \"second_id\"])\n",
    "    winning_cols = [c for c in adf.columns if c.startswith(\"W\")]\n",
    "    losing_cols = [c for c in adf.columns if c.startswith(\"L\")]\n",
    "    neutral_cols = [c for c in adf.columns if not(c.startswith(\"W\") or c.startswith(\"L\"))]\n",
    "\n",
    "    #Figure out location for losing team\n",
    "\n",
    "    df_w = adf[neutral_cols+winning_cols+[\"LScore\"]].copy()\n",
    "    df_l = adf[neutral_cols+losing_cols+[\"WScore\"]].copy()\n",
    "\n",
    "    df_w = df_w.rename(columns=lambda x:x[1:] if x.startswith(\"W\") else x)\n",
    "    df_l = df_l.rename(columns=lambda x:x[1:] if x.startswith(\"L\") else x)\n",
    "    df_l = df_l.rename(columns={\"WScore\":\"points_allowed\"})\n",
    "    df_w = df_w.rename(columns={\"LScore\":\"points_allowed\"})\n",
    "\n",
    "    df_w[\"result\"] = 1\n",
    "    df_l[\"result\"] = 0\n",
    "\n",
    "    df = pd.concat([df_w, df_l], ignore_index=True)\n",
    "    df = df.sort_values(by=[\"Season\", \"TeamID\", \"DayNum\"]).reset_index(drop=True)\n",
    "    display(df.isna().sum())\n",
    "    saved_df = df.copy()\n",
    "    df = saved_df.copy()\n",
    "    df = df.sort_values(by=[\"Season\", \"TeamID\", \"DayNum\"]).reset_index(drop=True)\n",
    "    stats = [\"Score\", \"FGM\", \"FGA\", \"FGM3\", \"FGA3\", \"FTM\", \"FTA\", \"OR\", \"DR\", \"Ast\", \"TO\", \"Stl\", \"Blk\", \"PF\", \"points_allowed\"]\n",
    "    cum_stats_cols = [f\"cum_{s}\" for s in stats]\n",
    "\n",
    "    for stat in stats:\n",
    "        df[f\"cum_{stat}\"] = df.groupby([\"Season\", \"TeamID\"])[stat].cumsum().shift(fill_value=0)\n",
    "\n",
    "    df[\"games_won\"] = df.groupby([\"Season\", \"TeamID\"])[\"result\"].cumsum().shift(fill_value=0)\n",
    "\n",
    "    df[\"games_played\"] = df.groupby([\"Season\", \"TeamID\"]).cumcount()\n",
    "\n",
    "    df[\"prev_TeamID\"] = df[\"TeamID\"].shift(1)\n",
    "    for stat in [*cum_stats_cols, \"games_played\", \"games_won\"]:\n",
    "        df.loc[df[\"TeamID\"] != df[\"prev_TeamID\"], stat] = 0\n",
    "\n",
    "    df[\"games_lost\"] = df[\"games_played\"] - df[\"games_won\"]\n",
    "\n",
    "    df[\"win_percentage\"] = df[\"games_won\"]/df[\"games_played\"]\n",
    "\n",
    "    df = df.drop(columns=[\"prev_TeamID\"])\n",
    "\n",
    "    df = pd.merge(df, conferences, how=\"left\", left_on=[\"Season\", \"TeamID\"], right_on=[\"Season\", \"TeamID\"])\n",
    "    print(df.columns)\n",
    "    df.head()\n",
    "    cum_stats = df.drop(columns=stats)\n",
    "\n",
    "    averages = [\"cum_Score\", \"cum_OR\", \"cum_DR\", \"cum_Ast\", \"cum_TO\", \"cum_Stl\", \"cum_Blk\", \"cum_PF\", \"cum_points_allowed\"]\n",
    "    percentages = [(\"cum_FGM\", \"cum_FGA\", \"FG%\"), (\"cum_FGM3\", \"cum_FGA3\", \"FG3%\"), (\"cum_FTM\", \"cum_FTA\", \"FT%\")]\n",
    "\n",
    "    print(cum_stats[cum_stats.games_played == 0].shape)\n",
    "\n",
    "    cum_stats = cum_stats[cum_stats.games_played != 0]\n",
    "\n",
    "    for col in averages:\n",
    "        colname = \"avg_\" + col[4:]\n",
    "        cum_stats[colname] = cum_stats[col] / cum_stats[\"games_played\"]\n",
    "\n",
    "    for make, attempt, new_col in percentages:\n",
    "        cum_stats[new_col] = cum_stats[make] / cum_stats[attempt]\n",
    "\n",
    "    averages = cum_stats.drop(columns=cum_stats_cols)\n",
    "\n",
    "    unimportant_cols = [\"prob\", \"NumOT\", \"result\", \"Loc\"]\n",
    "\n",
    "    averages_to_merge = averages.drop(columns=unimportant_cols)\n",
    "    safe = ['Season', 'DayNum', 'first_id', 'second_id', 'prob', 'game_id', 'NumOT']\n",
    "    fdf = all_matches[safe]\n",
    "    fdf.head()\n",
    "\n",
    "    df_merged = pd.merge(fdf, averages_to_merge, how=\"left\", left_on=[\"Season\", \"DayNum\", \"game_id\", \"first_id\"], right_on=[\"Season\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "    df_merged = df_merged.drop(columns=[\"TeamID\"])\n",
    "    for col in df_merged.columns:\n",
    "        if col not in safe:\n",
    "            df_merged[f\"first_{col}\"] = df_merged[col]\n",
    "            df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "    df_merged = pd.merge(df_merged, averages_to_merge, how=\"left\", left_on=[\"Season\", \"DayNum\", \"game_id\", \"second_id\"], right_on=[\"Season\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "    df_merged.drop(columns=[\"TeamID\"])\n",
    "    for col in df_merged.columns:\n",
    "        if col in safe or col.startswith(\"first_\"):\n",
    "            continue\n",
    "        df_merged[f\"second_{col}\"] = df_merged[col]\n",
    "        df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "    nfg_df = df_merged.dropna()\n",
    "    return nfg_df, averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df, cat):\n",
    "    not_needed = [\"Season\", \"first_id\", \"second_TeamID\", \"second_id\", \"game_id\", \"NumOT\", \"DayNum\"]\n",
    "\n",
    "    df = df.drop(columns=not_needed)\n",
    "\n",
    "    X = df.drop(columns=[\"prob\"])\n",
    "    y = df[\"prob\"]\n",
    "\n",
    "    # Identify categorical columns\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # ColumnTransformer to apply OneHotEncoder only to categorical columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
    "        ],\n",
    "        remainder=\"passthrough\"  # Keep non-categorical columns as they are\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': Integer(10, 1000),\n",
    "        'max_depth': Integer(3, 25),\n",
    "        'learning_rate': Real(0.01, 0.5, prior='log-uniform'),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'colsample_bytree': Real(0.5, 1.0)\n",
    "    }\n",
    "\n",
    "    classifier = XGBClassifier(device=\"cuda\")\n",
    "\n",
    "    grid_search = BayesSearchCV(classifier, param_grid, scoring=\"neg_brier_score\", cv=5, verbose=3, n_iter=25)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\", grid_search)  \n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    print(\"Best set of hyperparameters: \", pipe.named_steps[\"classifier\"].best_params_)\n",
    "    print(\"Best score: \", -pipe.named_steps[\"classifier\"].best_score_)\n",
    "\n",
    "    with open(f\"./model_params/{cat}_{datetime.isoformat(datetime.now())}.json\", \"w\") as f:\n",
    "        temp = pipe.named_steps[\"classifier\"].best_params_\n",
    "        temp[\"score\"] = -pipe.named_steps[\"classifier\"].best_score_\n",
    "        json.dump(temp, f)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(CATEGORY):\n",
    "    if CATEGORY == \"mens\":\n",
    "        season = pd.read_csv(\"./data/MRegularSeasonDetailedResults.csv\")\n",
    "        tournament = pd.read_csv(\"./data/MNCAATourneyDetailedResults.csv\")\n",
    "        conferences = pd.read_csv(\"./data/MTeamConferences.csv\")\n",
    "    else:\n",
    "        season = pd.read_csv(\"./data/WRegularSeasonDetailedResults.csv\")\n",
    "        tournament = pd.read_csv(\"./data/WNCAATourneyDetailedResults.csv\")\n",
    "        conferences = pd.read_csv(\"./data/WTeamConferences.csv\")\n",
    "    return season, tournament, conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(CATEGORY, averages, pipe):\n",
    "    submission = pd.read_csv(\"./data/SampleSubmissionStage2.csv\")\n",
    "    teams = pd.DataFrame(submission[\"ID\"].str.split(\"_\").to_list())\n",
    "    cols = [\"Season\", \"first_team_id\", \"second_team_id\"]\n",
    "    teams.columns = cols\n",
    "    teams = pd.concat([teams, submission], axis=1)\n",
    "    for c in cols:\n",
    "        teams[c] = teams[c].astype(\"int64\")\n",
    "\n",
    "    if CATEGORY == \"mens\":\n",
    "        teams = teams[teams.first_team_id < 2000]\n",
    "    else:\n",
    "        teams = teams[teams.first_team_id > 2000]\n",
    "\n",
    "    temp_avgs = averages.drop(columns=[\"NumOT\", \"prob\", \"Loc\", \"result\"])\n",
    "    data2025 = temp_avgs[temp_avgs.Season == 2025]\n",
    "    last_info = data2025.loc[data2025.groupby([\"TeamID\"])[\"DayNum\"].idxmax()]\n",
    "\n",
    "    d = pd.merge(teams, last_info, how=\"left\", left_on=\"first_team_id\", right_on=\"TeamID\", suffixes=(\"\", \"_first\"))\n",
    "    d=d.drop(columns=[\"Season_first\", \"DayNum\", \"TeamID\", \"game_id\"])\n",
    "    d.columns = [f\"first_{col}\" if col not in teams.columns else col for col in d.columns ]\n",
    "    d.head()\n",
    "    d = pd.merge(d, last_info, how=\"left\", left_on=\"second_team_id\", right_on=\"TeamID\", suffixes=(\"\", \"_second\"))\n",
    "    d = d.drop(columns=[\"Season_second\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "    d.columns = [f\"second_{col}\" if col in last_info.columns else col for col in d.columns ]\n",
    "    d = d.drop(columns=[\"second_Season\", \"first_team_id\", \"second_team_id\"])\n",
    "    d.head()\n",
    "\n",
    "    preds = pipe.predict_proba(d)[:,1]\n",
    "\n",
    "    teams[\"Pred\"] = preds\n",
    "\n",
    "    submission = teams[[\"ID\", \"Pred\"]]\n",
    "    return submission, teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tm_id(tm_name, cpy_tms):\n",
    "    cpy_tms = cpy_tms[[\"TeamName\", \"TeamID\"]]\n",
    "    return cpy_tms.loc[cpy_tms.TeamName == tm_name, \"TeamID\"].iloc[0]\n",
    "\n",
    "def get_result(round, team_df, map, team_names):\n",
    "    round = [\n",
    "        [map.get(round[0], round[0]), 0], \n",
    "        [map.get(round[1], round[1]), 0]\n",
    "    ]\n",
    "    round[0][1] = get_tm_id(round[0][0], team_names)\n",
    "    round[1][1] = get_tm_id(round[1][0], team_names)\n",
    "    round.sort(key=lambda x:x[1])\n",
    "    first = round[0][0]\n",
    "    second = round[1][0]\n",
    "    pred = team_df.loc[(team_df.first_team_name == first) & (team_df.second_team_name == second), \"Pred\"]\n",
    "    # print(pred)\n",
    "    pred = pred.iloc[0]\n",
    "    print(first if pred > .5 else  second, \"beat\", second if pred > .5 else first, \"with a prediction of\", pred if pred > .5 else 1-pred)\n",
    "    return first if pred > .5 else second\n",
    "\n",
    "\n",
    "def team_prediction(bracket, df, map, team_names):\n",
    "    # One round for play ins:\n",
    "    next_round = []\n",
    "    for tm in bracket:\n",
    "        winner = tm\n",
    "        if \"/\" in tm:\n",
    "            winner = get_result(tm.split(\"/\"), df, map, team_names)\n",
    "        next_round.append(winner)\n",
    "    bracket = next_round\n",
    "\n",
    "    #Loop through since they are all 0 when %2\n",
    "    while len(bracket) != 1:\n",
    "        next_round = []\n",
    "        while len(bracket) != 0:\n",
    "            curr_round = []\n",
    "            for i in range(2):\n",
    "                curr_round.append(bracket.pop(0))\n",
    "            winner = get_result(curr_round, df, map, team_names)\n",
    "            next_round.append(winner)\n",
    "        bracket = next_round\n",
    "\n",
    "def print_bracket_results(teams, CATEGORY, brck, bmap):\n",
    "\n",
    "    if CATEGORY == \"mens\":\n",
    "        tms = pd.read_csv(\"./data/MTeams.csv\")\n",
    "    else:\n",
    "        tms = pd.read_csv(\"./data/WTeams.csv\")\n",
    "\n",
    "\n",
    "    cpy_tms = tms.copy()\n",
    "    tms = tms[[\"TeamID\", \"TeamName\"]]\n",
    "\n",
    "    teams = teams.merge(tms, how=\"left\", left_on=\"first_team_id\", right_on=\"TeamID\")\n",
    "    teams[\"first_team_name\"] = teams.TeamName\n",
    "    teams = teams.drop(columns=[\"TeamName\", \"TeamID\"])\n",
    "\n",
    "    teams = teams.merge(tms, how=\"left\", left_on=\"second_team_id\", right_on=\"TeamID\")\n",
    "    teams[\"second_team_name\"] = teams.TeamName\n",
    "    teams = teams.drop(columns=[\"TeamName\", \"TeamID\"])\n",
    "\n",
    "    print(f\"{CATEGORY} BRACKET PREDICTIONS\")\n",
    "    team_prediction(brck, teams, bmap, cpy_tms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Season            0\n",
       "DayNum            0\n",
       "NumOT             0\n",
       "prob              0\n",
       "game_id           0\n",
       "TeamID            0\n",
       "Score             0\n",
       "Loc               0\n",
       "FGM               0\n",
       "FGA               0\n",
       "FGM3              0\n",
       "FGA3              0\n",
       "FTM               0\n",
       "FTA               0\n",
       "OR                0\n",
       "DR                0\n",
       "Ast               0\n",
       "TO                0\n",
       "Stl               0\n",
       "Blk               0\n",
       "PF                0\n",
       "points_allowed    0\n",
       "result            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'DayNum', 'NumOT', 'prob', 'game_id', 'TeamID', 'Score',\n",
      "       'Loc', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast',\n",
      "       'TO', 'Stl', 'Blk', 'PF', 'points_allowed', 'result', 'cum_Score',\n",
      "       'cum_FGM', 'cum_FGA', 'cum_FGM3', 'cum_FGA3', 'cum_FTM', 'cum_FTA',\n",
      "       'cum_OR', 'cum_DR', 'cum_Ast', 'cum_TO', 'cum_Stl', 'cum_Blk', 'cum_PF',\n",
      "       'cum_points_allowed', 'games_won', 'games_played', 'games_lost',\n",
      "       'win_percentage', 'ConfAbbrev'],\n",
      "      dtype='object')\n",
      "(7981, 28)\n",
      "Modeling...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.64918103501114, learning_rate=0.14481351804342968, max_depth=13, n_estimators=662, subsample=0.6746805074986886;, score=-0.237 total time=  28.7s\n",
      "[CV 2/5] END colsample_bytree=0.64918103501114, learning_rate=0.14481351804342968, max_depth=13, n_estimators=662, subsample=0.6746805074986886;, score=-0.240 total time=  23.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m df, averages \u001b[38;5;241m=\u001b[39m data_cleaning(season, tournament, conferences)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModeling...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking Predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m bmap, brck \u001b[38;5;241m=\u001b[39m get_bracket_data(cat)\n",
      "Cell \u001b[0;32mIn[62], line 40\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(df, cat)\u001b[0m\n\u001b[1;32m     33\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m BayesSearchCV(classifier, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_brier_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     35\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     36\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor),\n\u001b[1;32m     37\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search)  \n\u001b[1;32m     38\u001b[0m ])\n\u001b[0;32m---> 40\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m preds \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict_proba(test_X)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting set score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, brier_score_loss(test_y, preds))\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    661\u001b[0m         )\n\u001b[0;32m--> 662\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/skopt/searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/skopt/searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 599\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/skopt/searchcv.py:453\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    451\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[0;32m--> 453\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1597\u001b[0m )\n\u001b[0;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/march_madness/.venv/lib/python3.10/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running everything\n",
    "results = pd.DataFrame()\n",
    "for cat in [\"mens\", \"womens\"]:\n",
    "    print(\"Cleaning data...\")\n",
    "    season, tournament, conferences = get_data(cat)\n",
    "    df, averages = data_cleaning(season, tournament, conferences)\n",
    "    print(\"Modeling...\")\n",
    "    pipe = model(df, cat)\n",
    "    print(\"Making Predictions...\")\n",
    "    bmap, brck = get_bracket_data(cat)\n",
    "    submission, teams = make_predictions(cat, averages, pipe)\n",
    "    submission.to_csv(f\"./individual_submissions/{cat}_{datetime.isoformat(datetime.now())}\", index=False)\n",
    "    print_bracket_results(teams, cat, brck, bmap)\n",
    "    results = pd.concat([results, submission], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
