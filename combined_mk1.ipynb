{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning both Men and Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "season = pd.read_csv(\"./data/MRegularSeasonDetailedResults.csv\")\n",
    "wseason = pd.read_csv(\"./data/WRegularSeasonDetailedResults.csv\")\n",
    "season = pd.concat([season, wseason], axis=0)\n",
    "tournament = pd.read_csv(\"./data/MNCAATourneyDetailedResults.csv\")\n",
    "wtournament = pd.read_csv(\"./data/WNCAATourneyDetailedResults.csv\")\n",
    "tournament = pd.concat([tournament, wtournament], axis=0)\n",
    "conferences = pd.read_csv(\"./data/MTeamConferences.csv\")\n",
    "wconferences = pd.read_csv(\"./data/WTeamConferences.csv\")\n",
    "conferences = pd.concat([conferences, wconferences], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>LLoc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2003      10     1104      68     1328      62    N      0    27    58   \n",
       "1    2003      10     1272      70     1393      63    N      0    26    62   \n",
       "2    2003      11     1266      73     1437      61    N      0    24    58   \n",
       "3    2003      11     1296      56     1457      50    N      0    18    38   \n",
       "4    2003      11     1400      77     1208      71    N      0    30    61   \n",
       "\n",
       "   ...  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  LLoc  category  \n",
       "0  ...    22   10   22     8   18     9     2   20     N       men  \n",
       "1  ...    20   20   25     7   12     8     6   16     N       men  \n",
       "2  ...    23   31   22     9   12     2     5   23     N       men  \n",
       "3  ...    15   17   20     9   19     4     3   23     N       men  \n",
       "4  ...    27   21   15    12   10     7     1   14     N       men  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches = pd.concat([season, tournament], axis=0).sort_values([\"Season\", \"DayNum\"]).reset_index(drop=True)\n",
    "all_matches.tail()\n",
    "all_matches[\"LLoc\"] = all_matches.WLoc\n",
    "all_matches = all_matches.replace({\"LLoc\":{\"H\":\"A\", \"A\":\"H\", \"N\":\"N\"}})\n",
    "all_matches[\"category\"] = \"men\"\n",
    "all_matches.loc[all_matches.WTeamID > 2000, \"category\"] = \"women\"\n",
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>LLoc</th>\n",
       "      <th>category</th>\n",
       "      <th>first_id</th>\n",
       "      <th>second_id</th>\n",
       "      <th>prob</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "      <td>1104</td>\n",
       "      <td>1328</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1104_1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "      <td>1272</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1272_1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "      <td>1266</td>\n",
       "      <td>1437</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1266_1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "      <td>1296</td>\n",
       "      <td>1457</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1296_1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>men</td>\n",
       "      <td>1208</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1208_1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2003      10     1104      68     1328      62    N      0    27    58   \n",
       "1    2003      10     1272      70     1393      63    N      0    26    62   \n",
       "2    2003      11     1266      73     1437      61    N      0    24    58   \n",
       "3    2003      11     1296      56     1457      50    N      0    18    38   \n",
       "4    2003      11     1400      77     1208      71    N      0    30    61   \n",
       "\n",
       "   ...  LTO  LStl  LBlk  LPF  LLoc  category  first_id  second_id  prob  \\\n",
       "0  ...   18     9     2   20     N       men      1104       1328     1   \n",
       "1  ...   12     8     6   16     N       men      1272       1393     1   \n",
       "2  ...   12     2     5   23     N       men      1266       1437     1   \n",
       "3  ...   19     4     3   23     N       men      1296       1457     1   \n",
       "4  ...   10     7     1   14     N       men      1208       1400     0   \n",
       "\n",
       "          game_id  \n",
       "0  2003_1104_1328  \n",
       "1  2003_1272_1393  \n",
       "2  2003_1266_1437  \n",
       "3  2003_1296_1457  \n",
       "4  2003_1208_1400  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"Season\", \"first_id\", \"second_id\"]\n",
    "all_matches[\"first_id\"] = all_matches[['WTeamID','LTeamID']].min(axis=1)\n",
    "all_matches[\"second_id\"] = all_matches[['WTeamID','LTeamID']].max(axis=1)\n",
    "all_matches[\"prob\"] = 0\n",
    "all_matches.loc[all_matches.first_id == all_matches.WTeamID, \"prob\"] = 1\n",
    "all_matches[\"game_id\"] = all_matches[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving to first/second information and averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season            0\n",
       "DayNum            0\n",
       "NumOT             0\n",
       "category          0\n",
       "prob              0\n",
       "game_id           0\n",
       "TeamID            0\n",
       "Score             0\n",
       "Loc               0\n",
       "FGM               0\n",
       "FGA               0\n",
       "FGM3              0\n",
       "FGA3              0\n",
       "FTM               0\n",
       "FTA               0\n",
       "OR                0\n",
       "DR                0\n",
       "Ast               0\n",
       "TO                0\n",
       "Stl               0\n",
       "Blk               0\n",
       "PF                0\n",
       "points_allowed    0\n",
       "result            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adf = all_matches.drop(columns=[\"first_id\", \"second_id\"])\n",
    "winning_cols = [c for c in adf.columns if c.startswith(\"W\")]\n",
    "losing_cols = [c for c in adf.columns if c.startswith(\"L\")]\n",
    "neutral_cols = [c for c in adf.columns if not(c.startswith(\"W\") or c.startswith(\"L\"))]\n",
    "\n",
    "#Figure out location for losing team\n",
    "\n",
    "df_w = adf[neutral_cols+winning_cols+[\"LScore\"]].copy()\n",
    "df_l = adf[neutral_cols+losing_cols+[\"WScore\"]].copy()\n",
    "\n",
    "df_w = df_w.rename(columns=lambda x:x[1:] if x.startswith(\"W\") else x)\n",
    "df_l = df_l.rename(columns=lambda x:x[1:] if x.startswith(\"L\") else x)\n",
    "df_l = df_l.rename(columns={\"WScore\":\"points_allowed\"})\n",
    "df_w = df_w.rename(columns={\"LScore\":\"points_allowed\"})\n",
    "\n",
    "df_w[\"result\"] = 1\n",
    "df_l[\"result\"] = 0\n",
    "\n",
    "df = pd.concat([df_w, df_l], ignore_index=True)\n",
    "df = df.sort_values(by=[\"Season\", \"TeamID\", \"DayNum\"]).reset_index(drop=True)\n",
    "display(df.isna().sum())\n",
    "saved_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = saved_df.copy()\n",
    "df = df.sort_values(by=[\"Season\", \"TeamID\", \"DayNum\"]).reset_index(drop=True)\n",
    "stats = [\"Score\", \"FGM\", \"FGA\", \"FGM3\", \"FGA3\", \"FTM\", \"FTA\", \"OR\", \"DR\", \"Ast\", \"TO\", \"Stl\", \"Blk\", \"PF\", \"points_allowed\"]\n",
    "cum_stats_cols = [f\"cum_{s}\" for s in stats]\n",
    "\n",
    "for stat in stats:\n",
    "    df[f\"cum_{stat}\"] = df.groupby([\"Season\", \"TeamID\"])[stat].cumsum().shift(fill_value=0)\n",
    "\n",
    "df[\"games_won\"] = df.groupby([\"Season\", \"TeamID\"])[\"result\"].cumsum().shift(fill_value=0)\n",
    "\n",
    "df[\"games_played\"] = df.groupby([\"Season\", \"TeamID\"]).cumcount()\n",
    "\n",
    "df[\"prev_TeamID\"] = df[\"TeamID\"].shift(1)\n",
    "for stat in [*cum_stats_cols, \"games_played\", \"games_won\"]:\n",
    "    df.loc[df[\"TeamID\"] != df[\"prev_TeamID\"], stat] = 0\n",
    "\n",
    "df[\"games_lost\"] = df[\"games_played\"] - df[\"games_won\"]\n",
    "\n",
    "df[\"win_percentage\"] = df[\"games_won\"]/df[\"games_played\"]\n",
    "\n",
    "df = df.drop(columns=[\"prev_TeamID\"])\n",
    "\n",
    "df = pd.merge(df, conferences, how=\"left\", left_on=[\"Season\", \"TeamID\"], right_on=[\"Season\", \"TeamID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'DayNum', 'NumOT', 'category', 'prob', 'game_id', 'TeamID',\n",
      "       'Score', 'Loc', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR',\n",
      "       'Ast', 'TO', 'Stl', 'Blk', 'PF', 'points_allowed', 'result',\n",
      "       'cum_Score', 'cum_FGM', 'cum_FGA', 'cum_FGM3', 'cum_FGA3', 'cum_FTM',\n",
      "       'cum_FTA', 'cum_OR', 'cum_DR', 'cum_Ast', 'cum_TO', 'cum_Stl',\n",
      "       'cum_Blk', 'cum_PF', 'cum_points_allowed', 'games_won', 'games_played',\n",
      "       'games_lost', 'win_percentage', 'ConfAbbrev'],\n",
      "      dtype='object')\n",
      "(13583, 29)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()\n",
    "cum_stats = df.drop(columns=stats)\n",
    "\n",
    "averages = [\"cum_Score\", \"cum_OR\", \"cum_DR\", \"cum_Ast\", \"cum_TO\", \"cum_Stl\", \"cum_Blk\", \"cum_PF\", \"cum_points_allowed\"]\n",
    "percentages = [(\"cum_FGM\", \"cum_FGA\", \"FG%\"), (\"cum_FGM3\", \"cum_FGA3\", \"FG3%\"), (\"cum_FTM\", \"cum_FTA\", \"FT%\")]\n",
    "\n",
    "print(cum_stats[cum_stats.games_played == 0].shape)\n",
    "\n",
    "cum_stats = cum_stats[cum_stats.games_played != 0]\n",
    "\n",
    "for col in averages:\n",
    "    colname = \"avg_\" + col[4:]\n",
    "    cum_stats[colname] = cum_stats[col] / cum_stats[\"games_played\"]\n",
    "\n",
    "for make, attempt, new_col in percentages:\n",
    "    cum_stats[new_col] = cum_stats[make] / cum_stats[attempt]\n",
    "\n",
    "averages = cum_stats.drop(columns=cum_stats_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull this back to all_matches to have better historical data that we can calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_cols = [\"prob\", \"NumOT\", \"result\", \"Loc\", \"category\"]\n",
    "\n",
    "averages_to_merge = averages.drop(columns=unimportant_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>first_id</th>\n",
       "      <th>second_id</th>\n",
       "      <th>prob</th>\n",
       "      <th>game_id</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>category</th>\n",
       "      <th>first_games_won</th>\n",
       "      <th>first_games_played</th>\n",
       "      <th>...</th>\n",
       "      <th>second_avg_DR</th>\n",
       "      <th>second_avg_Ast</th>\n",
       "      <th>second_avg_TO</th>\n",
       "      <th>second_avg_Stl</th>\n",
       "      <th>second_avg_Blk</th>\n",
       "      <th>second_avg_PF</th>\n",
       "      <th>second_avg_points_allowed</th>\n",
       "      <th>second_FG%</th>\n",
       "      <th>second_FG3%</th>\n",
       "      <th>second_FT%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>1186</td>\n",
       "      <td>1457</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1186_1457</td>\n",
       "      <td>0</td>\n",
       "      <td>men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>1296</td>\n",
       "      <td>1458</td>\n",
       "      <td>0</td>\n",
       "      <td>2003_1296_1458</td>\n",
       "      <td>0</td>\n",
       "      <td>men</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>1125</td>\n",
       "      <td>1135</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1125_1135</td>\n",
       "      <td>1</td>\n",
       "      <td>men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>1156</td>\n",
       "      <td>1236</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1156_1236</td>\n",
       "      <td>0</td>\n",
       "      <td>men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>1161</td>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>2003_1161_1194</td>\n",
       "      <td>0</td>\n",
       "      <td>men</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  DayNum  first_id  second_id  prob         game_id  NumOT category  \\\n",
       "7     2003      12      1186       1457     1  2003_1186_1457      0      men   \n",
       "9     2003      12      1296       1458     0  2003_1296_1458      0      men   \n",
       "14    2003      14      1125       1135     1  2003_1125_1135      1      men   \n",
       "15    2003      14      1156       1236     1  2003_1156_1236      0      men   \n",
       "16    2003      14      1161       1194     1  2003_1161_1194      0      men   \n",
       "\n",
       "    first_games_won  first_games_played  ...  second_avg_DR  second_avg_Ast  \\\n",
       "7               0.0                 1.0  ...           20.0             9.0   \n",
       "9               1.0                 1.0  ...           24.0            12.0   \n",
       "14              0.0                 1.0  ...           21.0            17.0   \n",
       "15              0.0                 1.0  ...           21.0            11.0   \n",
       "16              1.0                 1.0  ...           22.0             9.0   \n",
       "\n",
       "   second_avg_TO  second_avg_Stl  second_avg_Blk  second_avg_PF  \\\n",
       "7           19.0             4.0             3.0           23.0   \n",
       "9            9.0             9.0             3.0           18.0   \n",
       "14          18.0             8.0             4.0           13.0   \n",
       "15          30.0            10.0             4.0           28.0   \n",
       "16          17.0             9.0             2.0           23.0   \n",
       "\n",
       "    second_avg_points_allowed  second_FG%  second_FG3%  second_FT%  \n",
       "7                        56.0    0.367347     0.272727    0.533333  \n",
       "9                        55.0    0.456140     0.500000    0.851852  \n",
       "14                       66.0    0.428571     0.315789    0.647059  \n",
       "15                       80.0    0.463415     0.266667    0.714286  \n",
       "16                       66.0    0.482759     0.454545    0.555556  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe = ['Season', 'DayNum', 'first_id', 'second_id', 'prob', 'game_id', 'NumOT', \"category\"]\n",
    "fdf = all_matches[safe]\n",
    "fdf.head()\n",
    "\n",
    "df_merged = pd.merge(fdf, averages_to_merge, how=\"left\", left_on=[\"Season\", \"DayNum\", \"game_id\", \"first_id\"], right_on=[\"Season\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "df_merged = df_merged.drop(columns=[\"TeamID\"])\n",
    "for col in df_merged.columns:\n",
    "    if col not in safe:\n",
    "        df_merged[f\"first_{col}\"] = df_merged[col]\n",
    "        df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "df_merged = pd.merge(df_merged, averages_to_merge, how=\"left\", left_on=[\"Season\", \"DayNum\", \"game_id\", \"second_id\"], right_on=[\"Season\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "df_merged.drop(columns=[\"TeamID\"])\n",
    "for col in df_merged.columns:\n",
    "    if col in safe or col.startswith(\"first_\"):\n",
    "        continue\n",
    "    df_merged[f\"second_{col}\"] = df_merged[col]\n",
    "    df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "nfg_df = df_merged.dropna()\n",
    "copy_dd = nfg_df.copy()\n",
    "copy_dd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned to remove first games, so very beginner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>category</th>\n",
       "      <th>first_games_won</th>\n",
       "      <th>first_games_played</th>\n",
       "      <th>first_games_lost</th>\n",
       "      <th>first_win_percentage</th>\n",
       "      <th>first_ConfAbbrev</th>\n",
       "      <th>first_avg_Score</th>\n",
       "      <th>first_avg_OR</th>\n",
       "      <th>first_avg_DR</th>\n",
       "      <th>...</th>\n",
       "      <th>second_avg_DR</th>\n",
       "      <th>second_avg_Ast</th>\n",
       "      <th>second_avg_TO</th>\n",
       "      <th>second_avg_Stl</th>\n",
       "      <th>second_avg_Blk</th>\n",
       "      <th>second_avg_PF</th>\n",
       "      <th>second_avg_points_allowed</th>\n",
       "      <th>second_FG%</th>\n",
       "      <th>second_FG3%</th>\n",
       "      <th>second_FT%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>big_sky</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>men</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mac</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a_sun</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>horizon</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>men</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mwc</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prob category  first_games_won  first_games_played  first_games_lost  \\\n",
       "7      1      men              0.0                 1.0               1.0   \n",
       "9      0      men              1.0                 1.0               0.0   \n",
       "14     1      men              0.0                 1.0               1.0   \n",
       "15     1      men              0.0                 1.0               1.0   \n",
       "16     1      men              1.0                 1.0               0.0   \n",
       "\n",
       "    first_win_percentage first_ConfAbbrev  first_avg_Score  first_avg_OR  \\\n",
       "7                    0.0          big_sky             55.0           6.0   \n",
       "9                    1.0              mac             56.0           6.0   \n",
       "14                   0.0            a_sun             48.0          14.0   \n",
       "15                   0.0          horizon             66.0          13.0   \n",
       "16                   1.0              mwc             80.0          13.0   \n",
       "\n",
       "    first_avg_DR  ...  second_avg_DR  second_avg_Ast  second_avg_TO  \\\n",
       "7           22.0  ...           20.0             9.0           19.0   \n",
       "9           19.0  ...           24.0            12.0            9.0   \n",
       "14          26.0  ...           21.0            17.0           18.0   \n",
       "15          26.0  ...           21.0            11.0           30.0   \n",
       "16          18.0  ...           22.0             9.0           17.0   \n",
       "\n",
       "    second_avg_Stl  second_avg_Blk  second_avg_PF  second_avg_points_allowed  \\\n",
       "7              4.0             3.0           23.0                       56.0   \n",
       "9              9.0             3.0           18.0                       55.0   \n",
       "14             8.0             4.0           13.0                       66.0   \n",
       "15            10.0             4.0           28.0                       80.0   \n",
       "16             9.0             2.0           23.0                       66.0   \n",
       "\n",
       "    second_FG%  second_FG3%  second_FT%  \n",
       "7     0.367347     0.272727    0.533333  \n",
       "9     0.456140     0.500000    0.851852  \n",
       "14    0.428571     0.315789    0.647059  \n",
       "15    0.463415     0.266667    0.714286  \n",
       "16    0.482759     0.454545    0.555556  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['prob', 'category', 'first_games_won', 'first_games_played',\n",
       "       'first_games_lost', 'first_win_percentage', 'first_ConfAbbrev',\n",
       "       'first_avg_Score', 'first_avg_OR', 'first_avg_DR', 'first_avg_Ast',\n",
       "       'first_avg_TO', 'first_avg_Stl', 'first_avg_Blk', 'first_avg_PF',\n",
       "       'first_avg_points_allowed', 'first_FG%', 'first_FG3%', 'first_FT%',\n",
       "       'second_games_won', 'second_games_played', 'second_games_lost',\n",
       "       'second_win_percentage', 'second_ConfAbbrev', 'second_avg_Score',\n",
       "       'second_avg_OR', 'second_avg_DR', 'second_avg_Ast', 'second_avg_TO',\n",
       "       'second_avg_Stl', 'second_avg_Blk', 'second_avg_PF',\n",
       "       'second_avg_points_allowed', 'second_FG%', 'second_FG3%', 'second_FT%'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "not_needed = [\"Season\", \"first_id\", \"second_TeamID\", \"second_id\", \"game_id\", \"NumOT\", \"DayNum\"]\n",
    "\n",
    "nfg_df = copy_dd.copy()\n",
    "\n",
    "nfg_df = nfg_df.drop(columns=not_needed)\n",
    "\n",
    "display(nfg_df.head())\n",
    "display(nfg_df.columns)\n",
    "\n",
    "X = nfg_df.drop(columns=[\"prob\"])\n",
    "y = nfg_df[\"prob\"]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# ColumnTransformer to apply OneHotEncoder only to categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # Keep non-categorical columns as they are\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madeline/march_madness/.venv/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:54:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.5369647833578984, learning_rate=0.11457442192929342, max_depth=7, n_estimators=988, subsample=0.7804716737752281;, score=-0.198 total time=  24.6s\n",
      "[CV 2/5] END colsample_bytree=0.5369647833578984, learning_rate=0.11457442192929342, max_depth=7, n_estimators=988, subsample=0.7804716737752281;, score=-0.198 total time=  17.9s\n",
      "[CV 3/5] END colsample_bytree=0.5369647833578984, learning_rate=0.11457442192929342, max_depth=7, n_estimators=988, subsample=0.7804716737752281;, score=-0.200 total time=  21.5s\n",
      "[CV 4/5] END colsample_bytree=0.5369647833578984, learning_rate=0.11457442192929342, max_depth=7, n_estimators=988, subsample=0.7804716737752281;, score=-0.199 total time=  18.2s\n",
      "[CV 5/5] END colsample_bytree=0.5369647833578984, learning_rate=0.11457442192929342, max_depth=7, n_estimators=988, subsample=0.7804716737752281;, score=-0.199 total time=  21.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.702347005177331, learning_rate=0.02051680314756331, max_depth=5, n_estimators=859, subsample=0.9853503272012993;, score=-0.189 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.702347005177331, learning_rate=0.02051680314756331, max_depth=5, n_estimators=859, subsample=0.9853503272012993;, score=-0.190 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.702347005177331, learning_rate=0.02051680314756331, max_depth=5, n_estimators=859, subsample=0.9853503272012993;, score=-0.192 total time=  10.6s\n",
      "[CV 4/5] END colsample_bytree=0.702347005177331, learning_rate=0.02051680314756331, max_depth=5, n_estimators=859, subsample=0.9853503272012993;, score=-0.191 total time=  10.4s\n",
      "[CV 5/5] END colsample_bytree=0.702347005177331, learning_rate=0.02051680314756331, max_depth=5, n_estimators=859, subsample=0.9853503272012993;, score=-0.189 total time=  13.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.887656553988541, learning_rate=0.018187568650780493, max_depth=23, n_estimators=24, subsample=0.8494214133534981;, score=-0.220 total time=  26.1s\n",
      "[CV 2/5] END colsample_bytree=0.887656553988541, learning_rate=0.018187568650780493, max_depth=23, n_estimators=24, subsample=0.8494214133534981;, score=-0.220 total time=  30.0s\n",
      "[CV 3/5] END colsample_bytree=0.887656553988541, learning_rate=0.018187568650780493, max_depth=23, n_estimators=24, subsample=0.8494214133534981;, score=-0.220 total time=  30.2s\n",
      "[CV 4/5] END colsample_bytree=0.887656553988541, learning_rate=0.018187568650780493, max_depth=23, n_estimators=24, subsample=0.8494214133534981;, score=-0.220 total time=  28.7s\n",
      "[CV 5/5] END colsample_bytree=0.887656553988541, learning_rate=0.018187568650780493, max_depth=23, n_estimators=24, subsample=0.8494214133534981;, score=-0.219 total time=  29.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5948922669190506, learning_rate=0.021512051949724286, max_depth=15, n_estimators=820, subsample=0.993688329298052;, score=-0.197 total time= 3.3min\n",
      "[CV 2/5] END colsample_bytree=0.5948922669190506, learning_rate=0.021512051949724286, max_depth=15, n_estimators=820, subsample=0.993688329298052;, score=-0.198 total time= 3.4min\n",
      "[CV 3/5] END colsample_bytree=0.5948922669190506, learning_rate=0.021512051949724286, max_depth=15, n_estimators=820, subsample=0.993688329298052;, score=-0.201 total time= 3.4min\n",
      "[CV 4/5] END colsample_bytree=0.5948922669190506, learning_rate=0.021512051949724286, max_depth=15, n_estimators=820, subsample=0.993688329298052;, score=-0.199 total time= 3.4min\n",
      "[CV 5/5] END colsample_bytree=0.5948922669190506, learning_rate=0.021512051949724286, max_depth=15, n_estimators=820, subsample=0.993688329298052;, score=-0.197 total time= 3.4min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8789497645374381, learning_rate=0.128429649883453, max_depth=4, n_estimators=836, subsample=0.7939076273371326;, score=-0.189 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=0.8789497645374381, learning_rate=0.128429649883453, max_depth=4, n_estimators=836, subsample=0.7939076273371326;, score=-0.190 total time=   8.2s\n",
      "[CV 3/5] END colsample_bytree=0.8789497645374381, learning_rate=0.128429649883453, max_depth=4, n_estimators=836, subsample=0.7939076273371326;, score=-0.192 total time=   8.3s\n",
      "[CV 4/5] END colsample_bytree=0.8789497645374381, learning_rate=0.128429649883453, max_depth=4, n_estimators=836, subsample=0.7939076273371326;, score=-0.190 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.8789497645374381, learning_rate=0.128429649883453, max_depth=4, n_estimators=836, subsample=0.7939076273371326;, score=-0.189 total time=   9.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5650894876103436, learning_rate=0.05901262512825338, max_depth=16, n_estimators=292, subsample=0.6110098389441511;, score=-0.199 total time= 1.2min\n",
      "[CV 2/5] END colsample_bytree=0.5650894876103436, learning_rate=0.05901262512825338, max_depth=16, n_estimators=292, subsample=0.6110098389441511;, score=-0.202 total time= 1.2min\n",
      "[CV 3/5] END colsample_bytree=0.5650894876103436, learning_rate=0.05901262512825338, max_depth=16, n_estimators=292, subsample=0.6110098389441511;, score=-0.202 total time= 1.3min\n",
      "[CV 4/5] END colsample_bytree=0.5650894876103436, learning_rate=0.05901262512825338, max_depth=16, n_estimators=292, subsample=0.6110098389441511;, score=-0.201 total time= 1.2min\n",
      "[CV 5/5] END colsample_bytree=0.5650894876103436, learning_rate=0.05901262512825338, max_depth=16, n_estimators=292, subsample=0.6110098389441511;, score=-0.200 total time= 1.2min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5530182000264164, learning_rate=0.10638892926691026, max_depth=19, n_estimators=749, subsample=0.8114349728328065;, score=-0.223 total time= 1.2min\n",
      "[CV 2/5] END colsample_bytree=0.5530182000264164, learning_rate=0.10638892926691026, max_depth=19, n_estimators=749, subsample=0.8114349728328065;, score=-0.225 total time= 1.2min\n",
      "[CV 3/5] END colsample_bytree=0.5530182000264164, learning_rate=0.10638892926691026, max_depth=19, n_estimators=749, subsample=0.8114349728328065;, score=-0.228 total time= 1.2min\n",
      "[CV 4/5] END colsample_bytree=0.5530182000264164, learning_rate=0.10638892926691026, max_depth=19, n_estimators=749, subsample=0.8114349728328065;, score=-0.223 total time= 1.2min\n",
      "[CV 5/5] END colsample_bytree=0.5530182000264164, learning_rate=0.10638892926691026, max_depth=19, n_estimators=749, subsample=0.8114349728328065;, score=-0.222 total time= 1.2min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8059907682313381, learning_rate=0.18721098229057043, max_depth=10, n_estimators=902, subsample=0.8784430258134379;, score=-0.224 total time=  25.3s\n",
      "[CV 2/5] END colsample_bytree=0.8059907682313381, learning_rate=0.18721098229057043, max_depth=10, n_estimators=902, subsample=0.8784430258134379;, score=-0.226 total time=  22.0s\n",
      "[CV 3/5] END colsample_bytree=0.8059907682313381, learning_rate=0.18721098229057043, max_depth=10, n_estimators=902, subsample=0.8784430258134379;, score=-0.228 total time=  24.8s\n",
      "[CV 4/5] END colsample_bytree=0.8059907682313381, learning_rate=0.18721098229057043, max_depth=10, n_estimators=902, subsample=0.8784430258134379;, score=-0.226 total time=  24.8s\n",
      "[CV 5/5] END colsample_bytree=0.8059907682313381, learning_rate=0.18721098229057043, max_depth=10, n_estimators=902, subsample=0.8784430258134379;, score=-0.224 total time=  22.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7953080300106363, learning_rate=0.30081159118670064, max_depth=19, n_estimators=270, subsample=0.9491990222571032;, score=-0.233 total time=  27.1s\n",
      "[CV 2/5] END colsample_bytree=0.7953080300106363, learning_rate=0.30081159118670064, max_depth=19, n_estimators=270, subsample=0.9491990222571032;, score=-0.235 total time=  27.3s\n",
      "[CV 3/5] END colsample_bytree=0.7953080300106363, learning_rate=0.30081159118670064, max_depth=19, n_estimators=270, subsample=0.9491990222571032;, score=-0.237 total time=  28.6s\n",
      "[CV 4/5] END colsample_bytree=0.7953080300106363, learning_rate=0.30081159118670064, max_depth=19, n_estimators=270, subsample=0.9491990222571032;, score=-0.235 total time=  28.4s\n",
      "[CV 5/5] END colsample_bytree=0.7953080300106363, learning_rate=0.30081159118670064, max_depth=19, n_estimators=270, subsample=0.9491990222571032;, score=-0.233 total time=  24.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.6582851906711934, learning_rate=0.01660147499612268, max_depth=20, n_estimators=86, subsample=0.8143145723640033;, score=-0.198 total time=  49.0s\n",
      "[CV 2/5] END colsample_bytree=0.6582851906711934, learning_rate=0.01660147499612268, max_depth=20, n_estimators=86, subsample=0.8143145723640033;, score=-0.199 total time=  46.4s\n",
      "[CV 3/5] END colsample_bytree=0.6582851906711934, learning_rate=0.01660147499612268, max_depth=20, n_estimators=86, subsample=0.8143145723640033;, score=-0.199 total time=  46.4s\n",
      "[CV 4/5] END colsample_bytree=0.6582851906711934, learning_rate=0.01660147499612268, max_depth=20, n_estimators=86, subsample=0.8143145723640033;, score=-0.199 total time=  48.8s\n",
      "[CV 5/5] END colsample_bytree=0.6582851906711934, learning_rate=0.01660147499612268, max_depth=20, n_estimators=86, subsample=0.8143145723640033;, score=-0.198 total time=  48.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=16, n_estimators=10, subsample=0.5586837109071267;, score=-0.241 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=16, n_estimators=10, subsample=0.5586837109071267;, score=-0.242 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=16, n_estimators=10, subsample=0.5586837109071267;, score=-0.242 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=16, n_estimators=10, subsample=0.5586837109071267;, score=-0.241 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=16, n_estimators=10, subsample=0.5586837109071267;, score=-0.241 total time=   3.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7907897095953454, learning_rate=0.1364814285502323, max_depth=9, n_estimators=574, subsample=0.7777041686773805;, score=-0.206 total time=  11.7s\n",
      "[CV 2/5] END colsample_bytree=0.7907897095953454, learning_rate=0.1364814285502323, max_depth=9, n_estimators=574, subsample=0.7777041686773805;, score=-0.205 total time=  11.5s\n",
      "[CV 3/5] END colsample_bytree=0.7907897095953454, learning_rate=0.1364814285502323, max_depth=9, n_estimators=574, subsample=0.7777041686773805;, score=-0.208 total time=  14.4s\n",
      "[CV 4/5] END colsample_bytree=0.7907897095953454, learning_rate=0.1364814285502323, max_depth=9, n_estimators=574, subsample=0.7777041686773805;, score=-0.206 total time=  11.7s\n",
      "[CV 5/5] END colsample_bytree=0.7907897095953454, learning_rate=0.1364814285502323, max_depth=9, n_estimators=574, subsample=0.7777041686773805;, score=-0.204 total time=  14.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9837133730405525, learning_rate=0.03693737127144906, max_depth=3, n_estimators=343, subsample=0.8015856003332188;, score=-0.193 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.9837133730405525, learning_rate=0.03693737127144906, max_depth=3, n_estimators=343, subsample=0.8015856003332188;, score=-0.194 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.9837133730405525, learning_rate=0.03693737127144906, max_depth=3, n_estimators=343, subsample=0.8015856003332188;, score=-0.196 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.9837133730405525, learning_rate=0.03693737127144906, max_depth=3, n_estimators=343, subsample=0.8015856003332188;, score=-0.195 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.9837133730405525, learning_rate=0.03693737127144906, max_depth=3, n_estimators=343, subsample=0.8015856003332188;, score=-0.193 total time=   2.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5034102539869647, learning_rate=0.01, max_depth=14, n_estimators=160, subsample=0.7604188606785887;, score=-0.197 total time=  33.1s\n",
      "[CV 2/5] END colsample_bytree=0.5034102539869647, learning_rate=0.01, max_depth=14, n_estimators=160, subsample=0.7604188606785887;, score=-0.198 total time=  32.7s\n",
      "[CV 3/5] END colsample_bytree=0.5034102539869647, learning_rate=0.01, max_depth=14, n_estimators=160, subsample=0.7604188606785887;, score=-0.198 total time=  32.9s\n",
      "[CV 4/5] END colsample_bytree=0.5034102539869647, learning_rate=0.01, max_depth=14, n_estimators=160, subsample=0.7604188606785887;, score=-0.198 total time=  32.8s\n",
      "[CV 5/5] END colsample_bytree=0.5034102539869647, learning_rate=0.01, max_depth=14, n_estimators=160, subsample=0.7604188606785887;, score=-0.196 total time=  32.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.7920881325070568, learning_rate=0.01, max_depth=3, n_estimators=296, subsample=1.0;, score=-0.200 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.7920881325070568, learning_rate=0.01, max_depth=3, n_estimators=296, subsample=1.0;, score=-0.201 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7920881325070568, learning_rate=0.01, max_depth=3, n_estimators=296, subsample=1.0;, score=-0.202 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7920881325070568, learning_rate=0.01, max_depth=3, n_estimators=296, subsample=1.0;, score=-0.202 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7920881325070568, learning_rate=0.01, max_depth=3, n_estimators=296, subsample=1.0;, score=-0.200 total time=   1.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8622498899584479, learning_rate=0.018496546223298226, max_depth=3, n_estimators=951, subsample=0.9449044622219075;, score=-0.192 total time=   4.6s\n",
      "[CV 2/5] END colsample_bytree=0.8622498899584479, learning_rate=0.018496546223298226, max_depth=3, n_estimators=951, subsample=0.9449044622219075;, score=-0.193 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.8622498899584479, learning_rate=0.018496546223298226, max_depth=3, n_estimators=951, subsample=0.9449044622219075;, score=-0.195 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.8622498899584479, learning_rate=0.018496546223298226, max_depth=3, n_estimators=951, subsample=0.9449044622219075;, score=-0.193 total time=   7.4s\n",
      "[CV 5/5] END colsample_bytree=0.8622498899584479, learning_rate=0.018496546223298226, max_depth=3, n_estimators=951, subsample=0.9449044622219075;, score=-0.192 total time=   4.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.8689229220558197, learning_rate=0.19329309762039174, max_depth=3, n_estimators=758, subsample=0.6579480807281366;, score=-0.189 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.8689229220558197, learning_rate=0.19329309762039174, max_depth=3, n_estimators=758, subsample=0.6579480807281366;, score=-0.190 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.8689229220558197, learning_rate=0.19329309762039174, max_depth=3, n_estimators=758, subsample=0.6579480807281366;, score=-0.192 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.8689229220558197, learning_rate=0.19329309762039174, max_depth=3, n_estimators=758, subsample=0.6579480807281366;, score=-0.190 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.8689229220558197, learning_rate=0.19329309762039174, max_depth=3, n_estimators=758, subsample=0.6579480807281366;, score=-0.189 total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.6686405958787691, learning_rate=0.014687744316249625, max_depth=12, n_estimators=639, subsample=0.8813632020550679;, score=-0.190 total time=  41.4s\n",
      "[CV 2/5] END colsample_bytree=0.6686405958787691, learning_rate=0.014687744316249625, max_depth=12, n_estimators=639, subsample=0.8813632020550679;, score=-0.191 total time=  44.4s\n",
      "[CV 3/5] END colsample_bytree=0.6686405958787691, learning_rate=0.014687744316249625, max_depth=12, n_estimators=639, subsample=0.8813632020550679;, score=-0.193 total time=  41.6s\n",
      "[CV 4/5] END colsample_bytree=0.6686405958787691, learning_rate=0.014687744316249625, max_depth=12, n_estimators=639, subsample=0.8813632020550679;, score=-0.192 total time=  41.4s\n",
      "[CV 5/5] END colsample_bytree=0.6686405958787691, learning_rate=0.014687744316249625, max_depth=12, n_estimators=639, subsample=0.8813632020550679;, score=-0.190 total time=  41.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9779040037234735, learning_rate=0.49999999999999994, max_depth=11, n_estimators=541, subsample=0.5;, score=-0.273 total time=  18.9s\n",
      "[CV 2/5] END colsample_bytree=0.9779040037234735, learning_rate=0.49999999999999994, max_depth=11, n_estimators=541, subsample=0.5;, score=-0.276 total time=  15.7s\n",
      "[CV 3/5] END colsample_bytree=0.9779040037234735, learning_rate=0.49999999999999994, max_depth=11, n_estimators=541, subsample=0.5;, score=-0.278 total time=  18.6s\n",
      "[CV 4/5] END colsample_bytree=0.9779040037234735, learning_rate=0.49999999999999994, max_depth=11, n_estimators=541, subsample=0.5;, score=-0.276 total time=  15.7s\n",
      "[CV 5/5] END colsample_bytree=0.9779040037234735, learning_rate=0.49999999999999994, max_depth=11, n_estimators=541, subsample=0.5;, score=-0.272 total time=  18.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.10580966962413053, max_depth=3, n_estimators=10, subsample=0.6940738004711169;, score=-0.212 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.10580966962413053, max_depth=3, n_estimators=10, subsample=0.6940738004711169;, score=-0.212 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.10580966962413053, max_depth=3, n_estimators=10, subsample=0.6940738004711169;, score=-0.213 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.10580966962413053, max_depth=3, n_estimators=10, subsample=0.6940738004711169;, score=-0.213 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.10580966962413053, max_depth=3, n_estimators=10, subsample=0.6940738004711169;, score=-0.212 total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9053338279689438, learning_rate=0.04804788810574227, max_depth=3, n_estimators=1000, subsample=0.6590479714730468;, score=-0.188 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.9053338279689438, learning_rate=0.04804788810574227, max_depth=3, n_estimators=1000, subsample=0.6590479714730468;, score=-0.189 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.9053338279689438, learning_rate=0.04804788810574227, max_depth=3, n_estimators=1000, subsample=0.6590479714730468;, score=-0.191 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=0.9053338279689438, learning_rate=0.04804788810574227, max_depth=3, n_estimators=1000, subsample=0.6590479714730468;, score=-0.189 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.9053338279689438, learning_rate=0.04804788810574227, max_depth=3, n_estimators=1000, subsample=0.6590479714730468;, score=-0.188 total time=   7.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.9679730748159964, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.6718831391780182;, score=-0.198 total time= 5.0min\n",
      "[CV 2/5] END colsample_bytree=0.9679730748159964, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.6718831391780182;, score=-0.200 total time= 5.0min\n",
      "[CV 3/5] END colsample_bytree=0.9679730748159964, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.6718831391780182;, score=-0.202 total time= 4.9min\n",
      "[CV 4/5] END colsample_bytree=0.9679730748159964, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.6718831391780182;, score=-0.200 total time= 4.9min\n",
      "[CV 5/5] END colsample_bytree=0.9679730748159964, learning_rate=0.01, max_depth=25, n_estimators=1000, subsample=0.6718831391780182;, score=-0.198 total time= 5.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8159011627871727;, score=-0.194 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8159011627871727;, score=-0.194 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8159011627871727;, score=-0.196 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8159011627871727;, score=-0.195 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8159011627871727;, score=-0.193 total time=   7.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5595188513906034, learning_rate=0.49999999999999994, max_depth=25, n_estimators=1000, subsample=0.6540974979241482;, score=-0.261 total time=  41.0s\n",
      "[CV 2/5] END colsample_bytree=0.5595188513906034, learning_rate=0.49999999999999994, max_depth=25, n_estimators=1000, subsample=0.6540974979241482;, score=-0.262 total time=  40.7s\n",
      "[CV 3/5] END colsample_bytree=0.5595188513906034, learning_rate=0.49999999999999994, max_depth=25, n_estimators=1000, subsample=0.6540974979241482;, score=-0.266 total time=  41.2s\n",
      "[CV 4/5] END colsample_bytree=0.5595188513906034, learning_rate=0.49999999999999994, max_depth=25, n_estimators=1000, subsample=0.6540974979241482;, score=-0.262 total time=  41.9s\n",
      "[CV 5/5] END colsample_bytree=0.5595188513906034, learning_rate=0.49999999999999994, max_depth=25, n_estimators=1000, subsample=0.6540974979241482;, score=-0.261 total time=  40.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.030140409917637077, max_depth=3, n_estimators=612, subsample=0.8234635145008444;, score=-0.191 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.030140409917637077, max_depth=3, n_estimators=612, subsample=0.8234635145008444;, score=-0.192 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.030140409917637077, max_depth=3, n_estimators=612, subsample=0.8234635145008444;, score=-0.194 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.030140409917637077, max_depth=3, n_estimators=612, subsample=0.8234635145008444;, score=-0.193 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.030140409917637077, max_depth=3, n_estimators=612, subsample=0.8234635145008444;, score=-0.191 total time=   6.0s\n",
      "Testing set score:  0.1890866299445825\n",
      "Best set of hyperparameters:  OrderedDict([('colsample_bytree', 0.9053338279689438), ('learning_rate', 0.04804788810574227), ('max_depth', 3), ('n_estimators', 1000), ('subsample', 0.6590479714730468)])\n",
      "Best score:  0.1892794604364652\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': Integer(10, 1000),\n",
    "    'max_depth': Integer(3, 25),\n",
    "    'learning_rate': Real(0.01, 0.5, prior='log-uniform'),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "    'colsample_bytree': Real(0.5, 1.0)\n",
    "}\n",
    "\n",
    "classifier = XGBClassifier(device=\"cuda\")\n",
    "\n",
    "grid_search = BayesSearchCV(classifier, param_grid, scoring=\"neg_brier_score\", cv=5, verbose=3, n_iter=25)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", grid_search)  \n",
    "])\n",
    "\n",
    "pipe.fit(train_X, train_y)\n",
    "\n",
    "preds = pipe.predict_proba(test_X)[:,1]\n",
    "\n",
    "print(\"Testing set score: \", brier_score_loss(test_y, preds))\n",
    "print(\"Best set of hyperparameters: \", pipe.named_steps[\"classifier\"].best_params_)\n",
    "print(\"Best score: \", -pipe.named_steps[\"classifier\"].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "with open(f\"./model_params/{datetime.isoformat(datetime.now())}.json\", \"w\") as f:\n",
    "    temp = pipe.named_steps[\"classifier\"].best_params_\n",
    "    temp[\"score\"] = -pipe.named_steps[\"classifier\"].best_score_\n",
    "    json.dump(temp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = pd.read_csv(\"./model_params/params.csv\")\n",
    "# #We want the best score, which is the smallest\n",
    "# params.sort_values(by=[\"score\"], inplace=True, ascending=True)\n",
    "# params.drop(columns=[\"score\"], inplace=True)\n",
    "# best_params = params.iloc[0].to_dict()\n",
    "# def convert_to_int_if_possible(d):\n",
    "#     for k, v in d.items():\n",
    "#         if isinstance(v, float) and v.is_integer():\n",
    "#             d[k] = int(v)\n",
    "#     return d\n",
    "# best_params = convert_to_int_if_possible(best_params)\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify categorical columns\n",
    "# categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# # ColumnTransformer to apply OneHotEncoder only to categorical columns\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
    "#     ],\n",
    "#     remainder=\"passthrough\"  # Keep non-categorical columns as they are\n",
    "# )\n",
    "\n",
    "# model = XGBClassifier(**best_params)\n",
    "\n",
    "# # Pipeline with OneHotEncoder and XGBoost\n",
    "# pipe = Pipeline([\n",
    "#     (\"preprocessing\", preprocessor),\n",
    "#     (\"classifier\", model)  # Add your hyperparameters here\n",
    "# ])\n",
    "\n",
    "# pipe.fit(train_X, train_y)\n",
    "\n",
    "# preds = pipe.predict_proba(test_X)[:,1]\n",
    "\n",
    "# onehot_columns = pipe.named_steps['preprocessing'].named_transformers_['onehot'].get_feature_names_out(categorical_features)\n",
    "# all_columns = list(onehot_columns) + list(X.select_dtypes(exclude=['object', 'category']).columns)\n",
    "\n",
    "# # Map feature importance to feature names\n",
    "# feature_important = model.get_booster().get_score(importance_type='weight')\n",
    "# feature_importance = {all_columns[int(k[1:])]: v for k, v in feature_important.items()}\n",
    "\n",
    "# keys = list(feature_importance.keys())\n",
    "# values = list(feature_importance.values())\n",
    "\n",
    "# data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "# display(data.head(25)) #Display the 25 most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>first_team_id</th>\n",
       "      <th>second_team_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131402</th>\n",
       "      <td>2025</td>\n",
       "      <td>3477</td>\n",
       "      <td>3479</td>\n",
       "      <td>2025_3477_3479</td>\n",
       "      <td>0.5</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131403</th>\n",
       "      <td>2025</td>\n",
       "      <td>3477</td>\n",
       "      <td>3480</td>\n",
       "      <td>2025_3477_3480</td>\n",
       "      <td>0.5</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131404</th>\n",
       "      <td>2025</td>\n",
       "      <td>3478</td>\n",
       "      <td>3479</td>\n",
       "      <td>2025_3478_3479</td>\n",
       "      <td>0.5</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131405</th>\n",
       "      <td>2025</td>\n",
       "      <td>3478</td>\n",
       "      <td>3480</td>\n",
       "      <td>2025_3478_3480</td>\n",
       "      <td>0.5</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131406</th>\n",
       "      <td>2025</td>\n",
       "      <td>3479</td>\n",
       "      <td>3480</td>\n",
       "      <td>2025_3479_3480</td>\n",
       "      <td>0.5</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season  first_team_id  second_team_id              ID  Pred category\n",
       "131402    2025           3477            3479  2025_3477_3479   0.5    women\n",
       "131403    2025           3477            3480  2025_3477_3480   0.5    women\n",
       "131404    2025           3478            3479  2025_3478_3479   0.5    women\n",
       "131405    2025           3478            3480  2025_3478_3480   0.5    women\n",
       "131406    2025           3479            3480  2025_3479_3480   0.5    women"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission = pd.read_csv(\"./data/SampleSubmissionStage2.csv\")\n",
    "teams = pd.DataFrame(submission[\"ID\"].str.split(\"_\").to_list())\n",
    "cols = [\"Season\", \"first_team_id\", \"second_team_id\"]\n",
    "teams.columns = cols\n",
    "teams = pd.concat([teams, submission], axis=1)\n",
    "for c in cols:\n",
    "    teams[c] = teams[c].astype(\"int64\")\n",
    "teams[\"category\"]  = \"mens\"\n",
    "teams.loc[teams.first_team_id > 2001 , \"category\"]  = \"women\"\n",
    "teams.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages.head()\n",
    "temp_avgs = averages.drop(columns=[\"NumOT\", \"prob\", \"Loc\", \"result\"])\n",
    "data2025 = temp_avgs[temp_avgs.Season == 2025]\n",
    "last_info = data2025.loc[data2025.groupby([\"TeamID\"])[\"DayNum\"].idxmax()]\n",
    "last_info = last_info.drop(columns=[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>category</th>\n",
       "      <th>first_games_won</th>\n",
       "      <th>first_games_played</th>\n",
       "      <th>first_games_lost</th>\n",
       "      <th>first_win_percentage</th>\n",
       "      <th>first_ConfAbbrev</th>\n",
       "      <th>first_avg_Score</th>\n",
       "      <th>first_avg_OR</th>\n",
       "      <th>...</th>\n",
       "      <th>second_avg_DR</th>\n",
       "      <th>second_avg_Ast</th>\n",
       "      <th>second_avg_TO</th>\n",
       "      <th>second_avg_Stl</th>\n",
       "      <th>second_avg_Blk</th>\n",
       "      <th>second_avg_PF</th>\n",
       "      <th>second_avg_points_allowed</th>\n",
       "      <th>second_FG%</th>\n",
       "      <th>second_FG3%</th>\n",
       "      <th>second_FT%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mens</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.44</td>\n",
       "      <td>wac</td>\n",
       "      <td>67.36</td>\n",
       "      <td>8.12</td>\n",
       "      <td>...</td>\n",
       "      <td>20.758621</td>\n",
       "      <td>13.379310</td>\n",
       "      <td>12.137931</td>\n",
       "      <td>5.689655</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>17.724138</td>\n",
       "      <td>73.172414</td>\n",
       "      <td>0.424676</td>\n",
       "      <td>0.336705</td>\n",
       "      <td>0.640301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mens</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.44</td>\n",
       "      <td>wac</td>\n",
       "      <td>67.36</td>\n",
       "      <td>8.12</td>\n",
       "      <td>...</td>\n",
       "      <td>25.518519</td>\n",
       "      <td>17.740741</td>\n",
       "      <td>12.185185</td>\n",
       "      <td>7.296296</td>\n",
       "      <td>3.703704</td>\n",
       "      <td>18.629630</td>\n",
       "      <td>75.592593</td>\n",
       "      <td>0.464675</td>\n",
       "      <td>0.355975</td>\n",
       "      <td>0.741573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mens</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.44</td>\n",
       "      <td>wac</td>\n",
       "      <td>67.36</td>\n",
       "      <td>8.12</td>\n",
       "      <td>...</td>\n",
       "      <td>28.428571</td>\n",
       "      <td>16.964286</td>\n",
       "      <td>12.535714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.607143</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>80.142857</td>\n",
       "      <td>0.485187</td>\n",
       "      <td>0.350236</td>\n",
       "      <td>0.722071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mens</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.44</td>\n",
       "      <td>wac</td>\n",
       "      <td>67.36</td>\n",
       "      <td>8.12</td>\n",
       "      <td>...</td>\n",
       "      <td>20.440000</td>\n",
       "      <td>12.720000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>8.360000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>22.160000</td>\n",
       "      <td>80.480000</td>\n",
       "      <td>0.390707</td>\n",
       "      <td>0.307210</td>\n",
       "      <td>0.672213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mens</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.44</td>\n",
       "      <td>wac</td>\n",
       "      <td>67.36</td>\n",
       "      <td>8.12</td>\n",
       "      <td>...</td>\n",
       "      <td>22.074074</td>\n",
       "      <td>11.037037</td>\n",
       "      <td>8.592593</td>\n",
       "      <td>7.296296</td>\n",
       "      <td>2.814815</td>\n",
       "      <td>18.703704</td>\n",
       "      <td>75.222222</td>\n",
       "      <td>0.398942</td>\n",
       "      <td>0.319728</td>\n",
       "      <td>0.690840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Pred category  first_games_won  first_games_played  \\\n",
       "0  2025_1101_1102   0.5     mens               11                  25   \n",
       "1  2025_1101_1103   0.5     mens               11                  25   \n",
       "2  2025_1101_1104   0.5     mens               11                  25   \n",
       "3  2025_1101_1105   0.5     mens               11                  25   \n",
       "4  2025_1101_1106   0.5     mens               11                  25   \n",
       "\n",
       "   first_games_lost  first_win_percentage first_ConfAbbrev  first_avg_Score  \\\n",
       "0                14                  0.44              wac            67.36   \n",
       "1                14                  0.44              wac            67.36   \n",
       "2                14                  0.44              wac            67.36   \n",
       "3                14                  0.44              wac            67.36   \n",
       "4                14                  0.44              wac            67.36   \n",
       "\n",
       "   first_avg_OR  ...  second_avg_DR  second_avg_Ast  second_avg_TO  \\\n",
       "0          8.12  ...      20.758621       13.379310      12.137931   \n",
       "1          8.12  ...      25.518519       17.740741      12.185185   \n",
       "2          8.12  ...      28.428571       16.964286      12.535714   \n",
       "3          8.12  ...      20.440000       12.720000      15.400000   \n",
       "4          8.12  ...      22.074074       11.037037       8.592593   \n",
       "\n",
       "   second_avg_Stl  second_avg_Blk  second_avg_PF  second_avg_points_allowed  \\\n",
       "0        5.689655        2.931034      17.724138                  73.172414   \n",
       "1        7.296296        3.703704      18.629630                  75.592593   \n",
       "2        6.000000        4.607143      18.857143                  80.142857   \n",
       "3        8.360000        3.800000      22.160000                  80.480000   \n",
       "4        7.296296        2.814815      18.703704                  75.222222   \n",
       "\n",
       "   second_FG%  second_FG3%  second_FT%  \n",
       "0    0.424676     0.336705    0.640301  \n",
       "1    0.464675     0.355975    0.741573  \n",
       "2    0.485187     0.350236    0.722071  \n",
       "3    0.390707     0.307210    0.672213  \n",
       "4    0.398942     0.319728    0.690840  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.merge(teams, last_info, how=\"left\", left_on=\"first_team_id\", right_on=\"TeamID\", suffixes=(\"\", \"_first\"))\n",
    "d=d.drop(columns=[\"Season_first\", \"DayNum\", \"TeamID\", \"game_id\"])\n",
    "d.columns = [f\"first_{col}\" if col not in teams.columns else col for col in d.columns ]\n",
    "d.head()\n",
    "d = pd.merge(d, last_info, how=\"left\", left_on=\"second_team_id\", right_on=\"TeamID\", suffixes=(\"\", \"_second\"))\n",
    "d = d.drop(columns=[\"Season_second\", \"DayNum\", \"game_id\", \"TeamID\"])\n",
    "d.columns = [f\"second_{col}\" if col in last_info.columns else col for col in d.columns ]\n",
    "d = d.drop(columns=[\"second_Season\", \"first_team_id\", \"second_team_id\"])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict_proba(d)[:,1]\n",
    "\n",
    "teams[\"Pred\"] = preds\n",
    "\n",
    "teams.head()\n",
    "\n",
    "copy_teams = teams.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = teams[[\"ID\", \"Pred\"]]\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "submission.to_csv(f\"./submissions/{datetime.isoformat(datetime.now())}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in Team Names from the actual brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>first_team_id</th>\n",
       "      <th>second_team_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>category</th>\n",
       "      <th>first_team_name</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1102</td>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.724173</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>1102</td>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1103</td>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.172730</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>1103</td>\n",
       "      <td>Akron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.113784</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>1104</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1105</td>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.712637</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>1105</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1106</td>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.559939</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>1106</td>\n",
       "      <td>Alabama St</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  first_team_id  second_team_id              ID      Pred category  \\\n",
       "0    2025           1101            1102  2025_1101_1102  0.724173     mens   \n",
       "1    2025           1101            1103  2025_1101_1103  0.172730     mens   \n",
       "2    2025           1101            1104  2025_1101_1104  0.113784     mens   \n",
       "3    2025           1101            1105  2025_1101_1105  0.712637     mens   \n",
       "4    2025           1101            1106  2025_1101_1106  0.559939     mens   \n",
       "\n",
       "  first_team_name  TeamID     TeamName  \n",
       "0     Abilene Chr    1102    Air Force  \n",
       "1     Abilene Chr    1103        Akron  \n",
       "2     Abilene Chr    1104      Alabama  \n",
       "3     Abilene Chr    1105  Alabama A&M  \n",
       "4     Abilene Chr    1106   Alabama St  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>first_team_id</th>\n",
       "      <th>second_team_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>category</th>\n",
       "      <th>first_team_name</th>\n",
       "      <th>second_team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1102</td>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.724173</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1103</td>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.172730</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Akron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.113784</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1105</td>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.712637</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1106</td>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.559939</td>\n",
       "      <td>mens</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama St</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  first_team_id  second_team_id              ID      Pred category  \\\n",
       "0    2025           1101            1102  2025_1101_1102  0.724173     mens   \n",
       "1    2025           1101            1103  2025_1101_1103  0.172730     mens   \n",
       "2    2025           1101            1104  2025_1101_1104  0.113784     mens   \n",
       "3    2025           1101            1105  2025_1101_1105  0.712637     mens   \n",
       "4    2025           1101            1106  2025_1101_1106  0.559939     mens   \n",
       "\n",
       "  first_team_name second_team_name  \n",
       "0     Abilene Chr        Air Force  \n",
       "1     Abilene Chr            Akron  \n",
       "2     Abilene Chr          Alabama  \n",
       "3     Abilene Chr      Alabama A&M  \n",
       "4     Abilene Chr       Alabama St  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = copy_teams.copy()\n",
    "\n",
    "tms = pd.read_csv(\"./data/MTeams.csv\")\n",
    "tms[\"category\"] = \"mens\"\n",
    "wteams = pd.read_csv(\"./data/WTeams.csv\")\n",
    "wteams[\"category\"] = \"women\"\n",
    "\n",
    "\n",
    "tms = pd.concat([tms, wteams], axis=0)\n",
    "cpy_tms = tms.copy()\n",
    "tms = tms[[\"TeamID\", \"TeamName\"]]\n",
    "\n",
    "teams = teams.merge(tms, how=\"left\", left_on=\"first_team_id\", right_on=\"TeamID\")\n",
    "teams[\"first_team_name\"] = teams.TeamName\n",
    "teams = teams.drop(columns=[\"TeamName\", \"TeamID\"])\n",
    "\n",
    "teams = teams.merge(tms, how=\"left\", left_on=\"second_team_id\", right_on=\"TeamID\")\n",
    "display(teams.head())\n",
    "teams[\"second_team_name\"] = teams.TeamName\n",
    "teams = teams.drop(columns=[\"TeamName\", \"TeamID\"])\n",
    "\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "mgames = \"\"\"\n",
    "1 Auburn vs. 16 Alabama State/St. Francis PA\n",
    "8 Louisville vs. 9 Creighton\n",
    "5 Michigan vs. 12 UC San Diego\n",
    "4 Texas A&M vs. 13 Yale\n",
    "6 Ole Miss vs. 11 SDSU/North Carolina\n",
    "3 Iowa State vs. 14 Lipscomb\n",
    "7 Marquette vs. 10 New Mexico\n",
    "2 Michigan State vs. 15 Bryant\n",
    "1 Florida vs. 16 Norfolk State\n",
    "8 UConn vs. 9 Oklahoma\n",
    "5 Memphis vs. 12 Colorado State\n",
    "4 Maryland vs. 13 Grand Canyon\n",
    "6 Missouri vs. 11 Drake\n",
    "3 Texas Tech vs. 14 UNC Wilmington\n",
    "7 Kansas vs. 10 Arkansas\n",
    "2 St. John’s vs. 15 Omaha\n",
    "1 Duke vs. 16 American/Mount St. Mary’s\n",
    "8 Mississippi State vs. 9 Baylor\n",
    "5 Oregon vs. 12 Liberty\n",
    "4 Arizona vs. 13 Akron\n",
    "6 BYU vs. 11 VCU\n",
    "3 Wisconsin vs. 14 Montana\n",
    "7 St. Mary’s vs. 10 Vanderbilt\n",
    "2 Alabama vs. 15 Robert Morris\n",
    "1 Houston vs. 16 SIUE\n",
    "8 Gonzaga vs. 9 Georgia\n",
    "5 Clemson vs. 12 McNeese\n",
    "4 Purdue vs. 13 High Point\n",
    "6 Illinois vs. 11 Texas/Xavier\n",
    "3 Kentucky vs. 14 Troy\n",
    "7 UCLA vs. 10 Utah State\n",
    "2 Tennessee vs. 15 Wofford\n",
    "\"\"\"\n",
    "\n",
    "matchups = mgames.split(\"\\n\")[1:-1]\n",
    "m = [m.split(\" vs. \") for m in matchups]\n",
    "mbrck = [re.sub(r'^\\d+\\s+', '', team) for pair in m for team in pair]\n",
    "\n",
    "\n",
    "\n",
    "mmap = {\n",
    "    \"Ole Miss\":\"Mississippi\",\n",
    "    \"Iowa State\":\"Iowa St\",\n",
    "    \"Michigan State\":\"Michigan St\",\n",
    "    \"Norfolk State\":\"Norfolk St\",\n",
    "    \"UConn\":\"Connecticut\",\n",
    "    \"Colorado State\":\"Colorado St\",\n",
    "    \"St. John’s\":\"St John's\",\n",
    "    \"Omaha\":\"NE Omaha\",\n",
    "    \"Mississippi State\":\"Mississippi St\",\n",
    "    \"St. Mary’s\":\"St Mary's CA\",\n",
    "    \"McNeese\":\"McNeese St\",\n",
    "    \"Utah State\":\"Utah St\",\n",
    "    \"SDSU\":\"South Dakota\",\n",
    "    \"Mount St. Mary’s\":\"Mt St Mary's\",\n",
    "    \"St. Francis PA\":\"St Francis PA\",\n",
    "    \"Alabama State\":\"Alabama St\",\n",
    "    \"American\":\"American Univ\"}\n",
    "\n",
    "wgames = \"\"\"\n",
    "No. 1 UCLA vs. No. 16 UC San Diego/Southern\n",
    "No. 8 Richmond vs. No. 9 Georgia Tech\n",
    "No. 4 Baylor vs. No. 13 Grand Canyon\n",
    "No. 5 Ole Miss vs. No. 12 Ball State\n",
    "No. 3 LSU vs. No. 14 San Diego State\n",
    "No. 6 Florida State vs. No. 11 George Mason\n",
    "No. 2 NC State vs. No. 15 Vermont\n",
    "No. 7 Michigan State vs. No. 10 Harvard\n",
    "No. 1 USC vs. No. 16 UNC Greensboro\n",
    "No. 8 California vs. No. 9 Mississippi State\n",
    "No. 4 Kentucky vs. No. 13 Liberty\n",
    "No. 5 Kansas State vs. No. 12 Fairfield\n",
    "No. 3 Oklahoma vs. No. 14 Florida Gulf Coast\n",
    "No. 6 Iowa vs. No. 11 Murray State\n",
    "No. 2 UConn vs. No. 15 Arkansas State\n",
    "No. 7 Oklahoma State vs. No. 10 South Dakota State\n",
    "No. 1 South Carolina vs. No. 16 Tennessee Tech\n",
    "No. 8 Utah vs. No. 9 Indiana\n",
    "No. 4 Maryland vs. No. 13 Norfolk State\n",
    "No. 5 Alabama vs. No. 12 Green Bay\n",
    "No. 3 North Carolina vs. No. 14 Oregon State\n",
    "No. 6 West Virginia vs. No. 11 Columbia/Washington\n",
    "No. 2 Duke vs. No. 15 Lehigh\n",
    "No. 7 Vanderbilt vs. No. 10 Oregon\n",
    "No. 1 Texas vs. No. 16 High Point/William & Mary\n",
    "No. 8 Illinois vs. No. 9 Creighton\n",
    "No. 4 Ohio State vs. No. 13 Montana State\n",
    "No. 5 Tennessee vs. No. 12 South Florida\n",
    "No. 3 Notre Dame vs. No. 14 Stephen F. Austin\n",
    "No. 6 Michigan vs. No. 11 Iowa State/Princeton\n",
    "No. 2 TCU vs. No. 15 Fairleigh Dickinson\n",
    "No. 7 Louisville vs. No. 10 Nebraska\n",
    "\"\"\"\n",
    "\n",
    "matchups = wgames.split(\"\\n\")[1:-1]\n",
    "m = [m.split(\" vs. \") for m in matchups]\n",
    "wbrck = [re.sub(r'^(No\\.\\s*)?\\d+\\s+', '', team).strip() for pair in m for team in pair]\n",
    "\n",
    "cpy_tms[cpy_tms.category == \"womens\"]\n",
    "\n",
    "wmap = {\n",
    "    \"Ole Miss\":\"Mississippi\",\n",
    "    \"Ball State\":\"Ball St\",\n",
    "    \"San Diego State\":\"San Diego St\",\n",
    "    \"Florida State\":\"Florida St\",\n",
    "    \"Michigan State\":\"Michigan St\",\n",
    "    \"Mississippi State\":\"Mississippi St\",\n",
    "    \"Kansas State\":\"Kansas St\",\n",
    "    \"Florida Gulf Coast\":\"FGCU\",\n",
    "    \"Murray State\":\"Murray St\",\n",
    "    \"UConn\":\"Connecticut\",\n",
    "    \"Arkansas State\":\"Arkansas St\",\n",
    "    \"Oklahoma State\":\"Oklahoma St\",\n",
    "    \"South Dakota State\":\"South Dakota\",\n",
    "    \"Norfolk State\":\"Norfolk St\",\n",
    "    \"Green Bay\":\"WI Green Bay\",\n",
    "    \"Oregon State\":\"Oregon St\",\n",
    "    \"Ohio State\":\"Ohio St\",\n",
    "    \"Montana State\":\"Montana St\",\n",
    "    \"Stephen F. Austin\":\"SF Austin\",\n",
    "    \"Fairleigh Dickinson\":\"F Dickinson\",\n",
    "    \"Iowa State\":\"Iowa St\",\n",
    "    \"Southern\":\"Southern Univ\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENS BRACKET PREDICTIONS\n",
      "Alabama St beat St Francis PA with a prediction of 0.57993364\n",
      "North Carolina beat South Dakota with a prediction of 0.7788093\n",
      "American Univ beat Mt St Mary's with a prediction of 0.50358266\n",
      "Xavier beat Texas with a prediction of 0.5242547\n",
      "Auburn beat Alabama St with a prediction of 0.9574302\n",
      "Louisville beat Creighton with a prediction of 0.5921706\n",
      "Michigan beat UC San Diego with a prediction of 0.5298722\n",
      "Yale beat Texas A&M with a prediction of 0.58564204\n",
      "Mississippi beat North Carolina with a prediction of 0.5704852\n",
      "Iowa St beat Lipscomb with a prediction of 0.6801576\n",
      "Marquette beat New Mexico with a prediction of 0.5002581\n",
      "Michigan St beat Bryant with a prediction of 0.8614514\n",
      "Florida beat Norfolk St with a prediction of 0.84622407\n",
      "Connecticut beat Oklahoma with a prediction of 0.7361547\n",
      "Memphis beat Colorado St with a prediction of 0.5427419\n",
      "Maryland beat Grand Canyon with a prediction of 0.7673852\n",
      "Missouri beat Drake with a prediction of 0.60302055\n",
      "Texas Tech beat UNC Wilmington with a prediction of 0.6754127\n",
      "Kansas beat Arkansas with a prediction of 0.58521926\n",
      "St John's beat NE Omaha with a prediction of 0.88608533\n",
      "Duke beat American Univ with a prediction of 0.96160805\n",
      "Mississippi St beat Baylor with a prediction of 0.6231552\n",
      "Oregon beat Liberty with a prediction of 0.69378644\n",
      "Arizona beat Akron with a prediction of 0.6195016\n",
      "VCU beat BYU with a prediction of 0.57826036\n",
      "Wisconsin beat Montana with a prediction of 0.8431394\n",
      "St Mary's CA beat Vanderbilt with a prediction of 0.54969275\n",
      "Alabama beat Robert Morris with a prediction of 0.68685216\n",
      "Houston beat SIUE with a prediction of 0.8982831\n",
      "Gonzaga beat Georgia with a prediction of 0.7103778\n",
      "Clemson beat McNeese St with a prediction of 0.56530106\n",
      "Purdue beat High Point with a prediction of 0.6413449\n",
      "Illinois beat Xavier with a prediction of 0.50913584\n",
      "Kentucky beat Troy with a prediction of 0.6377772\n",
      "Utah St beat UCLA with a prediction of 0.50329363\n",
      "Tennessee beat Wofford with a prediction of 0.8546169\n",
      "Auburn beat Louisville with a prediction of 0.68483776\n",
      "Michigan beat Yale with a prediction of 0.51563245\n",
      "Iowa St beat Mississippi with a prediction of 0.6529106\n",
      "Michigan St beat Marquette with a prediction of 0.67488855\n",
      "Florida beat Connecticut with a prediction of 0.63564974\n",
      "Maryland beat Memphis with a prediction of 0.7378359\n",
      "Texas Tech beat Missouri with a prediction of 0.56462866\n",
      "St John's beat Kansas with a prediction of 0.6747515\n",
      "Duke beat Mississippi St with a prediction of 0.7442901\n",
      "Arizona beat Oregon with a prediction of 0.5198806\n",
      "Wisconsin beat VCU with a prediction of 0.5908844\n",
      "Alabama beat St Mary's CA with a prediction of 0.51854646\n",
      "Houston beat Gonzaga with a prediction of 0.5306022\n",
      "Clemson beat Purdue with a prediction of 0.5876149\n",
      "Illinois beat Kentucky with a prediction of 0.6018376\n",
      "Tennessee beat Utah St with a prediction of 0.6196148\n",
      "Auburn beat Michigan with a prediction of 0.6807577\n",
      "Michigan St beat Iowa St with a prediction of 0.56055903\n",
      "Maryland beat Florida with a prediction of 0.5244585\n",
      "St John's beat Texas Tech with a prediction of 0.51734984\n",
      "Duke beat Arizona with a prediction of 0.75445724\n",
      "Alabama beat Wisconsin with a prediction of 0.51250976\n",
      "Houston beat Clemson with a prediction of 0.5992802\n",
      "Tennessee beat Illinois with a prediction of 0.6516556\n",
      "Auburn beat Michigan St with a prediction of 0.575757\n",
      "St John's beat Maryland with a prediction of 0.52716476\n",
      "Duke beat Alabama with a prediction of 0.6991918\n",
      "Houston beat Tennessee with a prediction of 0.53897935\n",
      "Auburn beat St John's with a prediction of 0.54248995\n",
      "Duke beat Houston with a prediction of 0.6387502\n",
      "Duke beat Auburn with a prediction of 0.6081306\n",
      "WOMENS BRACKET PREDICTIONS\n",
      "UC San Diego beat Southern Univ with a prediction of 0.60919493\n",
      "Washington beat Columbia with a prediction of 0.5854249\n",
      "High Point beat William & Mary with a prediction of 0.6669385\n",
      "Princeton beat Iowa St with a prediction of 0.5091876\n",
      "UCLA beat UC San Diego with a prediction of 0.9524655\n",
      "Georgia Tech beat Richmond with a prediction of 0.5144302\n",
      "Baylor beat Grand Canyon with a prediction of 0.7557273\n",
      "Mississippi beat Ball St with a prediction of 0.7467193\n",
      "LSU beat San Diego St with a prediction of 0.8490037\n",
      "Florida St beat George Mason with a prediction of 0.61632967\n",
      "NC State beat Vermont with a prediction of 0.74618775\n",
      "Michigan St beat Harvard with a prediction of 0.74302185\n",
      "USC beat UNC Greensboro with a prediction of 0.919601\n",
      "California beat Mississippi St with a prediction of 0.50103897\n",
      "Kentucky beat Liberty with a prediction of 0.8036264\n",
      "Kansas St beat Fairfield with a prediction of 0.71933055\n",
      "Oklahoma beat FGCU with a prediction of 0.65701133\n",
      "Iowa beat Murray St with a prediction of 0.51506925\n",
      "Connecticut beat Arkansas St with a prediction of 0.9621095\n",
      "Oklahoma St beat South Dakota with a prediction of 0.9692469\n",
      "South Carolina beat Tennessee Tech with a prediction of 0.9147228\n",
      "Utah beat Indiana with a prediction of 0.7273829\n",
      "Maryland beat Norfolk St with a prediction of 0.5972915\n",
      "Alabama beat WI Green Bay with a prediction of 0.6714616\n",
      "North Carolina beat Oregon St with a prediction of 0.91211027\n",
      "West Virginia beat Washington with a prediction of 0.701372\n",
      "Duke beat Lehigh with a prediction of 0.80960935\n",
      "Vanderbilt beat Oregon with a prediction of 0.7303407\n",
      "Texas beat High Point with a prediction of 0.97132695\n",
      "Illinois beat Creighton with a prediction of 0.536191\n",
      "Ohio St beat Montana St with a prediction of 0.7467431\n",
      "Tennessee beat South Florida with a prediction of 0.7666998\n",
      "Notre Dame beat SF Austin with a prediction of 0.81797606\n",
      "Princeton beat Michigan with a prediction of 0.52114344\n",
      "TCU beat F Dickinson with a prediction of 0.925777\n",
      "Louisville beat Nebraska with a prediction of 0.5122215\n",
      "UCLA beat Georgia Tech with a prediction of 0.77771586\n",
      "Baylor beat Mississippi with a prediction of 0.6444975\n",
      "LSU beat Florida St with a prediction of 0.60545766\n",
      "Michigan St beat NC State with a prediction of 0.55349416\n",
      "USC beat California with a prediction of 0.8143333\n",
      "Kansas St beat Kentucky with a prediction of 0.77561295\n",
      "Oklahoma beat Iowa with a prediction of 0.7040609\n",
      "Connecticut beat Oklahoma St with a prediction of 0.8099048\n",
      "South Carolina beat Utah with a prediction of 0.7468747\n",
      "Alabama beat Maryland with a prediction of 0.5124185\n",
      "West Virginia beat North Carolina with a prediction of 0.5458478\n",
      "Duke beat Vanderbilt with a prediction of 0.55656105\n",
      "Texas beat Illinois with a prediction of 0.88227177\n",
      "Ohio St beat Tennessee with a prediction of 0.5562883\n",
      "Notre Dame beat Princeton with a prediction of 0.8132398\n",
      "TCU beat Louisville with a prediction of 0.86716676\n",
      "UCLA beat Baylor with a prediction of 0.62350154\n",
      "LSU beat Michigan St with a prediction of 0.57682765\n",
      "USC beat Kansas St with a prediction of 0.5134743\n",
      "Connecticut beat Oklahoma with a prediction of 0.79724514\n",
      "South Carolina beat Alabama with a prediction of 0.7467873\n",
      "Duke beat West Virginia with a prediction of 0.55873775\n",
      "Texas beat Ohio St with a prediction of 0.79314137\n",
      "TCU beat Notre Dame with a prediction of 0.5865166\n",
      "UCLA beat LSU with a prediction of 0.6287117\n",
      "Connecticut beat USC with a prediction of 0.6397976\n",
      "South Carolina beat Duke with a prediction of 0.704687\n",
      "Texas beat TCU with a prediction of 0.57747835\n",
      "Connecticut beat UCLA with a prediction of 0.60419744\n",
      "Texas beat South Carolina with a prediction of 0.65785074\n",
      "Connecticut beat Texas with a prediction of 0.51936406\n"
     ]
    }
   ],
   "source": [
    "def get_tm_id(cat, tm_name, cpy_tms):\n",
    "    cpy_tms = cpy_tms[[\"category\", \"TeamName\", \"TeamID\"]]\n",
    "    mtms = cpy_tms[cpy_tms[\"category\"] == cat]\n",
    "    return mtms.loc[mtms.TeamName == tm_name, \"TeamID\"].iloc[0]\n",
    "\n",
    "def get_result(round, team_df, map, cat, team_names):\n",
    "    round = [\n",
    "        [map.get(round[0], round[0]), 0], \n",
    "        [map.get(round[1], round[1]), 0]\n",
    "    ]\n",
    "    round[0][1] = get_tm_id(cat, round[0][0], team_names)\n",
    "    round[1][1] = get_tm_id(cat, round[1][0], team_names)\n",
    "    round.sort(key=lambda x:x[1])\n",
    "    first = round[0][0]\n",
    "    second = round[1][0]\n",
    "    pred = team_df.loc[(team_df.first_team_name == first) & (team_df.second_team_name == second), \"Pred\"]\n",
    "    # print(pred)\n",
    "    pred = pred.iloc[0]\n",
    "    print(first if pred > .5 else  second, \"beat\", second if pred > .5 else first, \"with a prediction of\", pred if pred > .5 else 1-pred)\n",
    "    return first if pred > .5 else second\n",
    "\n",
    "\n",
    "def team_prediction(bracket, cat, df, map, team_names):\n",
    "    # One round for play ins:\n",
    "    team_df = df[df.category == cat]\n",
    "    next_round = []\n",
    "    for tm in bracket:\n",
    "        winner = tm\n",
    "        if \"/\" in tm:\n",
    "            winner = get_result(tm.split(\"/\"), team_df, map, cat, team_names)\n",
    "        next_round.append(winner)\n",
    "    bracket = next_round\n",
    "\n",
    "    #Loop through since they are all 0 when %2\n",
    "    while len(bracket) != 1:\n",
    "        next_round = []\n",
    "        while len(bracket) != 0:\n",
    "            curr_round = []\n",
    "            for i in range(2):\n",
    "                curr_round.append(bracket.pop(0))\n",
    "            winner = get_result(curr_round, team_df, map, cat, team_names)\n",
    "            next_round.append(winner)\n",
    "        bracket = next_round\n",
    "\n",
    "print(\"MENS BRACKET PREDICTIONS\")\n",
    "team_prediction(mbrck, \"mens\", teams, mmap, cpy_tms)\n",
    "print(\"WOMENS BRACKET PREDICTIONS\")\n",
    "team_prediction(wbrck, \"women\", teams, wmap, cpy_tms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
